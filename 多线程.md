# 进程与线程基本概念

## 进程产生的背景

最初的计算机只能接受一些特定的指令，用户每输入一个指令，计算机就做出一个操作。当用户在思考或者输入时，计算机就在等待。这样效率非常低下，在很多时候，计算机都处在等待状态。

**批处理操作系统**

后来有了批处理操作系统把一系列需要操作的指令写下来，形成一个清单，一次性交给计算机。用户将多个需要执行的程序写在磁带上，然后交由计算机去读取并逐个执行这些程序，并将输出结果写在另一个磁带上

批处理操偶做系统在一定程度上提高了计算机的效率，但是由于批处理操作系统的指令运行方式仍然是串行的，内存中始终只有一个程序在运行，后面的程序需要等待前面的程序执行完成后才能开始执行，而前面的程序有时会由于I/O操作、网络等原因阻塞，所以批处理操作系统效率也不高。

**进程的提出**

人们对于计算机的性能要求越来越高，现有的批处理操作系统并不能满足人们的需求，而批处理操作系统的瓶颈在于内存中只存在一个程序，那么内存中能不能存在多个程序呢？这是人们待解决的问题。

于是，科学家们提出了进程的概念。

进程就是应用程序在内存中分配的空间，也就是正在运行的程序，哥哥进程之间互不干扰。同时进程保存着程序每一时刻运行的状态。

> 程序：用某种编程语言(Java,python等)编写，能够完成一定任务或者功能的代码集合，是指令和数据的有序集合，是一段静态代码。

此时，CPU采用时间片轮转的方式运行进程：CPU为每个进程分配一个时间段，称作它的时间片。如果在时间片结束是进程还在运行，则暂停这个进程的运行，并且CPU分配给另一个进程(这个过程叫做上下文切换)。如果进程在时间片结束前阻塞或结束，额CPU立即进行切换，不用等待时间片用完。

> 当进程暂停时，它会保存当前进程的状态(进程标识，进程使用的资源等)，在下一次切换回来时根据之前保存的状态进行恢复，接着继续执行。

使用进程+CPU时间片轮转方式的操作系统，在宏观上看起来同一时间段执行多个任务，换句话说，进程让操作系统的并发成为了可能。虽然并发从宏观上看有多个任务在执行，但在事实上，对于单核CPU来说，任意具体时刻都只有一个任务在占用CPU资源。

**对操作系统的要求进一步提高**

虽然进程的出现，使得操作系统的性能大大提升，但是随着时间的推移，人们并不满足一个进程在一段时间只能做一件事情，如果一个进程有多个子任务时，只能诸个得执行这些子任务，很影响效率。

> 比如杀毒软件在检测用户电脑时，如果在某一项检测中卡住了，那么后面的检测箱也会受到影响。或者说当你使用杀毒软件中的扫描病毒功能时，在扫描病毒结束之前，无法使用杀毒软件清理垃圾的功能，这显然无法满足人们的要求。

**线程的提出**

那么能不能让这些子任务同时执行呢？于是人们又提出了线程的概念，让一个线程执行一个子任务，这样一个进程就包含了多个线程，每个线程负责一个单独的子任务。

> 使用线程之后，事情就变得简单多了。当用户使用扫描病毒时功能时，就让扫描病毒这个线程去执行。同时，如果用户又使用清理垃圾功能，那么可以先暂停扫描病毒线程，先响应用户的清理垃圾的操作，让清理垃圾这个线程去执行。响应完后再切换回来，接着执行扫描病毒线程。
> 注意：操作系统是如何分配时间片给每一个线程的，涉及到线程的调度策略

总之，进程和线程的提出极大的提高了操作提供的性能。进程让操作系统的并发性成为了可能，而线程让进程的内部并发成为了可能。

**多进程也可以实现并发，为什么我们要使用多线程？**

多进程方式确实可以实现并发，但使用多线程，有以下几个好处:

+ 进程间的通信比较复杂，而线程间的通信比较简单，通常情况夏，我们需要使用共享资源，这些资源在线程间的通信比较容易。
+ 进程是重量级的，而线程是轻量级的，故多线程的系统开销更小。

**进程和线程的区别**

进程是一个独立的运行环境，而线程是在进程中执行的一个任务。他们两个本质的区别是是否单独占有内存地址空间及其它系统资源(比如I/O)

+ 进程单独占有一定的额内存地址空间，所以进程间存在内存隔离，数据是分开的，数据共享复杂但是同步简单，哥哥进程间互不干扰；而线程共享所属进程占有的内存地址空间和资源，数据共享简单，但是同步复杂。
+ 进程单独占有一定的内存地址空间，一个进程出现问题不会影响其他进程，不影响主程序的稳定性，可靠性高；一个线程崩溃可能影响整个程序的稳定性，可靠性较低。
+ 进程单独占有一定的内存地址空间，进程的创建和销毁不仅需要保存寄存器和栈信息，还需要资源的分配回收以及页调度，开销较大；线程只需要保存寄存器和栈信息，开销较小。

另外一个重要区别是，进程是操作系统进行资源分配的基本单位，而线程是操作系统进行调度的基本单位，即CPU分配时间的单位。

## 上下文切换

上下文切换(有时也称作进程切换或任务切换)是指CPU从一个进程(或线程)切换到另一个进程(或线程)。上下文是指某一时间点CPU寄存器和程序计数器的内容。

> 寄存器是CPU内部的少量的速度很快的内存，通常存储和访问计算过程的中间值提高计算机程序的运行速度。
> 程序计数器是一个专用的寄存器，用于表明指令序列中CPU正在执行的位置或者下一个将要被执行的指令的位置，具体实现依赖于特定的系统。
> 举例说明 线程A - B
> 1. 先挂起线程A，将其在CPU中的状态保存在内存中。
> 2. 在内存中检索下一个线程B的上下文并将其在CPU的寄存器中恢复执行B线程。
> 3. 当B执行完，根据程序计数器中的指向的文职恢复线程A

CPU通过为每个线程分配CPU时间片来实现多线程机制。CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。

但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换。

上下文切换通常时计算密集型的，以为这此操作会消耗大量的CPU时间，故限额很难过也不是越多越好。如何减少系统红上下文切换次数，是提升多线程性能的一个重点课题。

# Java多线程入门类和接口

## Thread类和Runnable接口

上一章我们；了解了操作系统中多线程的基本概念。那么在Java中，我们是如何使用多线程的呢？

首先，我们需要有一个“线程”类。JDK提供了Thread类和Runnable接口来让我们实现自己的线程类

+ 继承Thread类，并重写run方法；
+ 实现Runnable接口的run方法；

### 继承Thread类

先学会怎么用，再学原理。首先我们来看看怎么用Thread和Runnable来写一个JAVA多线程程序.

首先是继承`Thread`类

```java
public class demo1 {

    public static class MyThread extends Thread {
        @Override
        public void run() {
            System.out.println("执行demo方法");
        }
    }

    public static void main(String[] args) {
        MyThread thread = new MyThread();
        thread.start();
    }
}
```

注意要调用start()方法后，该线程才算启动!

> 我们在程序里面调用了start()方法后，虚拟机会先为我们创建一个线程。然后等到这个线程第一次得到时间片时再调用run()方法。
> 注意不可多次调用start()方法。在第一次调用start方法之后，再次调用start()方法会出现异常。


### 实现Runnable接口

接着我们来看一下`Runnable`接口(JDKK 1.8+)

```java
@FunctionalInterface
public interface Runnable {
    public abstract void run();
}
```

可以看到`Runnable`是一个函数式接口，这意味我们可以使用Java8的函数式编程来简化代码

**示例代码**

```java
public class demo2 {

    public static class MyThread implements Runnable {
        @Override
        public void run() {
            System.out.println("MyThread");
        }
    }
    public static void main(String[] args) {
        new Thread(new MyThread()).start();
        // Java 8 函数式编程，可以省略MyThread类
        new Thread(() -> {
            System.out.println("Java 8 匿名内部类");
        }).start();
    }
}
```

### Thread类构造方法

`Thread`类是一个`Runnable`接口的实现类，查看`Thread`类的构造方法，发现其实是简单调用一个私有的`init`方法来实现初始化。`init`的方法签名:

```java
// Thread类源码 

// 片段1 - init方法
private void init(ThreadGroup g, Runnable target, String name,
                      long stackSize, AccessControlContext acc,
                      boolean inheritThreadLocals)

// 片段2 - 构造函数调用init方法
public Thread(Runnable target) {
    init(null, target, "Thread-" + nextThreadNum(), 0);
}

// 片段3 - 使用在init方法里初始化AccessControlContext类型的私有属性
this.inheritedAccessControlContext = 
    acc != null ? acc : AccessController.getContext();

// 片段4 - 两个对用于支持ThreadLocal的私有属性
ThreadLocal.ThreadLocalMap threadLocals = null;
ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
```

`init`方法的参数:

+ g:线程组，指定这个线程是在哪个线程组下;
+ target:指定要执行的线程任务
+ name:线程的名字，多个线程的名字是可以重复的。如果不指定没名字，见片段2；
+ acc:见片段3，用于初始化私有变量`inheritedAccessControlContext`。
  
  > 这个变量有点神奇。它是一个私有变量，但是在Thread类里只有init方法对它进行初始化，在exit方法把它设为null。其它没有任何地方使用它。一般我们是不会使用它的，那什么时候会使用到这个变量呢？可以参考这个stackoverflow的问题：Restrict permissions to threads which execute third party software；
+ inheritThreadLocals:可继承的`ThreadLocal`,见片段4，`Thread`类里面有两个私有属性来支持`ThreadLocal`,我们会在后面的章节介绍`ThreadLocal`的概念。

实际情况下，我们大多是直接调用下面两个构造方法:

```java
Thread(Runnable target)
Thread(Runnable target, String name)
```


### Thread类的几个常用方法

这里介绍一下Thread类的几个常用的方法:

+ currentThread()：静态方法，返回对当前正在执行的线程对象的引用；
+ start():开始执行线程的方法，java虚拟机会调用线程内的run()方法；
+ yield():yield在英语里有放弃的意思，同样，这里的yield()指的是当前线程愿意让出对当前处理器的占用。这里需要注意的是，就算当前线程调用了yield()方法，程序在调度的时候，也还有可能继续运行这个线程的。
+ sleep():静态方法，使当前线睡眠一段时间。
+ join():使当前线程等待另一个线程执行完毕之后再继续执行，内部调用的是Object类的wait方法实现的；

### Thread类和Runnable接口的比较:

实现一个自定义的线程类，可以有继承`Thread`类或者实现`Runnable`接口这两种方式，他们之间有什么优劣呢？

+ 由于Java单继承，多实现的特性，Runnable接口使用起来比Thread更灵活。
+ Runnable接口出现更符合面向对象，将线程单独进行对象的封装。
+ Runnablle接口出现，降低了线程对象和线程任务的耦合性。
+ 如果使用线程时不需要使用Thread类的诸多方法，显然使用Runnabel接口更为轻量。

所以，我们通常优先使用“实现Runnable接口”这种方式来自定义线程类。

## Callable、Future与FutureTask

通常来说，我们使用`Runnable`和`Thread`来创建一个新的线程。但是他们有一个弊端，就是run方法是没有返回值的。而有时候我们希望开启一个线程去执行一个任务，并且这个任务执行完成后有一个返回值。

JDK提供了`Callable`接口与`Future`类为我们解决这个问题，这也是所谓的“异步”模型。

### Callable接口

Callable与Runnable类似，同样是只有一个抽象方法的函数式接口。不同的是，Callable提供的方法是有返回值的，而且支持泛型。


```java
@FunctionalInterface
public interface Callable<V> {
    V call() throws Exception;
}
```

那一般是怎么使用Callable的呢？Callable一般是配合线程池工具`ExecutorService`来使用的。我们会在后续章节解释线程池的使用。这里只介绍`ExecutorService`可以使用`submit`来让一个`Callable`接口执行。它会返回一个Future,我们后续的程序可以通过这个`Future`的get方法得到结果。

这里可以看一个简单的使用demo:

```java
import java.util.concurrent.*;

public class demo3 implements Callable<Integer> {


    @Override
    public Integer call() throws Exception {
        Thread.sleep(2000);
        return 2;
    }

    public static void main(String[] args) throws ExecutionException, InterruptedException {
        ExecutorService executorService = Executors.newCachedThreadPool();
        demo3 demo3 = new demo3();
        Future<Integer> submit = executorService.submit(demo3);
        Integer integer = submit.get();
        System.out.println(integer);
    }
}

```

### Future接口

`Future`接口只有几个比较简单的方法：

```java
public abstract interface Future<V> {
    public abstract boolean cancel(boolean paramBoolean);
    public abstract boolean isCancelled();
    public abstract boolean isDone();
    public abstract V get() throws InterruptedException, ExecutionException;
    public abstract V get(long paramLong, TimeUnit paramTimeUnit)
            throws InterruptedException, ExecutionException, TimeoutException;
}
```

`cancel`方法是试图取消一个线程的执行。

注意是试图取消，并不一定能取消成功。因为任务可能已完成、已取消、或者一些其它因素不能取消，存在取消失败的可能。boolean类型的返回值是"是否取消成功"的意思。参数paramBoolean表示是否采用中断的方式取消线程执行。

所以有时候，为了让任务有能够取消的，就使用Callable来代替Runnable。如果为了可取消性而使用Future但又不提供可用的结果，则可以声明Future<?>形式类型、并返回null作为底层任务的结果。


### FutureTask类

上面介绍了Future接口。这个接口有一个实现类叫FutureTask。FutureTask是实现的RunnableFuture接口的，而RunnableFuture接口同时继承了Runnable接口和Future接口：

```java
public interface RunnableFuture<V> extends Runnable, Future<V> {
    /**
     * Sets this Future to the result of its computation
     * unless it has been cancelled.
     */
    void run();
}
```

那FutureTask类有什么用？为什么要有一个FutureTask类?前面说到了Future只是一个接口，而它里面的cancel，get,isDone等方法要自己实现起来都是非常复杂的。所以JDK提供了一个FutureTask类来供我们使用。

示例代码:

```java
import java.util.concurrent.*;

public class demo4 implements Callable<Integer> {
    @Override
    public Integer call() throws Exception {
        //模拟计算需要一秒
        Thread.sleep(1000);
        return 2;
    }

    public static void main(String[] args) throws ExecutionException, InterruptedException {
        //使用
        ExecutorService executorService = Executors.newCachedThreadPool();
        FutureTask<Integer> integerFutureTask = new FutureTask<>(new demo4());
        executorService.submit(integerFutureTask);
        System.out.println(integerFutureTask.get());
    }
}
```

使用上与第一个Demo有一点小的区别。首先，带哦用submit方法是没有返回值的。这里实际上是调用的submit(Runnable task)方法，而上面的Demo,调用的是submit(Callable<T> task)方法。

然后，这里是使用FutureTask直接取get取值，而上面的Demo是通过submit方法返回的Future取值。

在很多高并发的环境下，有可能Callable和FutureTask会创建多次。FutureTask能够在高并发环境下确保任务只执行一次。这块有兴趣的同学可以参看FutureTask的源码。


### FutureTask的几个状态

```java
/**
  *
  * state可能的状态转变路径如下：
  * NEW -> COMPLETING -> NORMAL
  * NEW -> COMPLETING -> EXCEPTIONAL
  * NEW -> CANCELLED
  * NEW -> INTERRUPTING -> INTERRUPTED
  */
private volatile int state;
private static final int NEW          = 0;
private static final int COMPLETING   = 1;
private static final int NORMAL       = 2;
private static final int EXCEPTIONAL  = 3;
private static final int CANCELLED    = 4;
private static final int INTERRUPTING = 5;
private static final int INTERRUPTED  = 6;
```

> state表示任务的运行状态，初始状态为NEW。运行状态只会在set、setException、cancel方法中终止。COMPLETING、INTERRUPTING是任务完成后的瞬时状态。




# 线程组和线程优先级

## 线程组(ThreadGroup)

Java中用ThreadGroup来表示线程组，我们可以使用线程组来对线程进行批量控制。

ThreadGroup和Thread的关系就如同他们的字面意思一样简单粗暴，每个Thread必然存在于一个ThreadGroup中，Thread不能独立于ThreadGroup存在。执行main()方法线程的名字是main,如果在new Thread时没有显式指定，那么默认将父线程（当前执行new Thread的线程）线程组设置为自己的线程组。

示例代码：

```java
public class Demo {
    public static void main(String[] args) {
        Thread testThread = new Thread(() -> {
            System.out.println("testThread当前线程组名字：" +
                    Thread.currentThread().getThreadGroup().getName());
            System.out.println("testThread线程名字：" +
                    Thread.currentThread().getName());
        });

        testThread.start();
        System.out.println("执行main方法线程名字：" + Thread.currentThread().getName());
    }
}
```

输出结果:

```
执行main方法线程名字：main
testThread当前线程组名字：main
testThread线程名字：Thread-0
```

ThreadGroup管理者它下面的Thread,ThreadGroup是一个标准的向下引用的树状结构，这样设计的原因是防止"上级"线程被"下级"线程引用而无法有效地被CG回收。

## 线程的优先级

Java中线程优先级可以指定，范围是1~10。但是并不是所有的操作系统都支持10级优先级的划分(比如有些操作系统只支持3级划分：低，中，高)，Java只是给操作系统一个优先级的参考值，线程最终在操作系统的优先级是多少还是由操作系统决定。

Java默认的线程优先级为5，线程的执行顺序由调度程序来决定，线程的优先级会在线程被调用之前设定。

通常情况下，高优先级的线程将会比低优先级的线程有更高的机率得到执行。我们使用Thread类的setPriority()实例方法来设定线程的优先级。

```java
public class Demo {
    public static void main(String[] args) {
        Thread a = new Thread();
        System.out.println("我是默认线程优先级："+a.getPriority());
        Thread b = new Thread();
        b.setPriority(10);
        System.out.println("我是设置过的线程优先级："+b.getPriority());
    }
}
```

既然有1-10的级别来设定了线程的优先级，这时候可能有些读者会问，那么我是不是可以在业务实现的时候，采用这种方法来指定一些线程执行的先后顺序?

对于这个问题，我们的答案是:No!

Java中的优先级来说不是特定的可靠，Java程序中对线程所设置的优先级只是给操作系统一个建议，操作系统不一定会采纳。而真正的调用顺序，是由操作系统的线程调度算法决定的。

示例代码:

```java
import java.util.stream.IntStream;

public class demo6 {

    public static class T1 extends Thread{
        @Override
        public void run() {
            super.run();
            System.out.println(String.format("当前执行的线程是：%s，优先级：%d",
                    Thread.currentThread().getName(),
                    Thread.currentThread().getPriority()));
        }
    }

    public static void main(String[] args) {
        IntStream.range(1,10).forEach(i -> {
            Thread thread = new Thread(new T1());
            thread.setPriority(i);
            thread.start();
        });
    }
}

```

Java提供一个线程调度器来监视和控制处于RUNNABLE状态的线程。线程的调度策略采用抢占式，优先级高的线程比优先级低的线程会有更大的几率优先执行。在优先级相同的情况下，按照“先到先得”的原则。每个Java程序都有一个默认的主线程，就是通过JVM启动的第一个现车给main线程。

还有一种线程成为守护线程(Daemon),守护线程默认的优先级比较低。

> 如果某线程是守护线程，那如果所在的非守护线程结束，这个守护线程也会自动结束。
> 应用场景：当所有非守护线程结束时，结束其余的子线程（守护线程）自动关闭，就免去了还要继续关闭子线程的麻烦。
> 一个线程默认是非守护线程，可以通过Thread类的setDaemon(boolean on)来设置。

在之前，我们有谈到一个线程必然存在与一个线程组中，那么当线程和线程组得优先级不一致的时候将会怎样呢?我们用下面的案例来验证一下:

```java
public static void main(String[] args) {
    ThreadGroup threadGroup = new ThreadGroup("t1");
    threadGroup.setMaxPriority(6);
    Thread thread = new Thread(threadGroup,"thread");
    thread.setPriority(9);
    System.out.println("我是线程组的优先级"+threadGroup.getMaxPriority());
    System.out.println("我是线程的优先级"+thread.getPriority());
}
```

所以，如果某个线程优先级大于线程所在线程组的最大优先级，那么该线程的优先级将会失效，取而代之的是线程组的最大优先级。



## 线程组的常用方法及数据结构

### 线程组的常用方法

获取当前的线程组名称

```java
Thread.currentThread().getThreadGroup().getName();
```

复制线程组

```java
Thread[] threads = new Thread[threadGroup.activeCount()];

ThreadGroup threadGroup1 = new ThreadGroup("t2");

threadGroup1.enumerate(threads);
```

线程组统一异常处理

```java
public class demo8 {

    public static void main(String[] args) {
        ThreadGroup threadGroup1 = new ThreadGroup("group1"){
            @Override
            public void uncaughtException(Thread t, Throwable e) {
                //继承ThreadGroup并重新定义以下方法
                //在线程成员抛出unchecked exception
                //会执行此方法
                System.out.println(t.getName() + ":"+e.getMessage());
            }
        };

        //这个线程是threadGroup1的一员
        Thread thread = new Thread(threadGroup1, new Runnable() {
            @Override
            public void run() {
                //抛出unchecked异常
                throw new RuntimeException("测试异常");
            }
        });

        thread.start();
    }
}
```

### 线程组的数据结构
线程组还可以包含其它的线程组，不仅仅是线程。

首先看看`ThreadGroup`源码中的成员变量

```java
public class ThreadGroup implements Thread.UncaughtExceptionHandler {
    private final ThreadGroup parent; // 父亲ThreadGroup
    String name; // ThreadGroup 的名称
    int maxPriority; // 线程最大优先级
    boolean destroyed; // 是否被销毁
    boolean daemon; // 是否守护线程
    boolean vmAllowSuspension; // 是否可以中断

    int nUnstartedThreads = 0; // 还未启动的线程
    int nthreads; // ThreadGroup中线程数目
    Thread threads[]; // ThreadGroup中的线程

    int ngroups; // 线程组数目
    ThreadGroup groups[]; // 线程组数组
}
```

然后看看构造函数

```java
// 私有构造函数
private ThreadGroup() { 
    this.name = "system";
    this.maxPriority = Thread.MAX_PRIORITY;
    this.parent = null;
}

// 默认是以当前ThreadGroup传入作为parent  ThreadGroup，新线程组的父线程组是目前正在运行线程的线程组。
public ThreadGroup(String name) {
    this(Thread.currentThread().getThreadGroup(), name);
}

// 构造函数
public ThreadGroup(ThreadGroup parent, String name) {
    this(checkParentAccess(parent), parent, name);
}

// 私有构造函数，主要的构造函数
private ThreadGroup(Void unused, ThreadGroup parent, String name) {
    this.name = name;
    this.maxPriority = parent.maxPriority;
    this.daemon = parent.daemon;
    this.vmAllowSuspension = parent.vmAllowSuspension;
    this.parent = parent;
    parent.add(this);
}
```

第三个构造函数里调用了checkParentAccess方法，这里看看这个方法的源码:

```java
// 检查parent ThreadGroup
private static Void checkParentAccess(ThreadGroup parent) {
    parent.checkAccess();
    return null;
}

// 判断当前运行的线程是否具有修改线程组的权限
public final void checkAccess() {
    SecurityManager security = System.getSecurityManager();
    if (security != null) {
        security.checkAccess(this);
    }
}
```

> 这里涉及到`SecurityManager`这个类，它是Java的安全管理器，它允许应用程序子啊执行一个可能不安全或敏感的操作前确定该操作是什么，以及是否是在允许执行该操作的安全上下文中执行它。应用程序可以允许或不允许该操作。
> 比如引入了第三方类库，但是并不能保证它的安全性。
> 其实Thread类也有一个checkAccess()方法，不过是用来当前运行的线程是否有权限修改被调用的这个线程实例。(Determines if the currently running thread has permission to modify this thread)

总结来说，线程组是一个树状的结构，每个线程组下面可以有多个线程或者线程组。线程组可以起到统一控制线程的优先级和检查线程的权限的作用。


# Java线程的状态及主要转化方法

## 4.1操作系统中的线程状态转换

首先我们来看看操作系统中的线程状态转换。

> 在现在的操作系统中，线程是被视为轻量级进程的，所以操作系统线程的状态其实和操作系统进程的状态是一致的。

![img](D:\file\note\study-note\多线程.assets\assets%2F-L_5HvtIhTFW9TQlOF8e%2F-L_5TIKcBFHWPtY3OwUo%2F-L_5TJM1VhwmwbNGzqwJ%2F系统进程状态转换图.png)

操作系统线程主要有以下三个状态:

+ 就绪状态(ready):线程正在等待使用CPU，经调度程序调用之后可进入running状态。
+ 执行状态(running):线程正在使用CPU。
+ 等待状态(waiting):线程经过等待事件的调用或者正在等待其他资源(如I/O)。


## Java线程的6个状态

```java
// Thread.State 源码
public enum State {
    NEW,
    RUNNABLE,
    BLOCKED,
    WAITING,
    TIMED_WAITING,
    TERMINATED;
}
```

### NEW

处于NEW状态的线程此时尚未启动。这里的尚未启动指的是还没屌用Thread实力的start()方法。

```java
private void testStateNew() {
    Thread thread = new Thread(() -> {});
    System.out.println(thread.getState()); // 输出 NEW 
}
```

从上面可以看出，只是创建了线程而并没有调用start()方法，此时线程处于NEW状态。

关于start()的两个引申问题

1. 反复调用同一个线程的start()方法是否可行?
2. 假如一个线程执行完毕(此时处于TERMINATED状态)，再次调用这个线程的start()方法是否可行

要分析这两个问题，我们先来看看start()的源码:

```java
public synchronized void start() {
    if (threadStatus != 0)
        throw new IllegalThreadStateException();

    group.add(this);

    boolean started = false;
    try {
        start0();
        started = true;
    } finally {
        try {
            if (!started) {
                group.threadStartFailed(this);
            }
        } catch (Throwable ignore) {

        }
    }
}
```

我们可以看到，在start()内部，这里有一个threadStatus的变量。如果它不等于0，调用start()是会直接抛出异常的。

我们接着往下看，有一个native的start0()方法。这个方法里并没有对threadStatus的处理。到了这里我们仿佛就拿这个threadStatus没辙了，我们通过debug的方式再看一下:

```java
@Test
public void testStartMethod() {
    Thread thread = new Thread(() -> {});
    thread.start(); // 第一次调用
    thread.start(); // 第二次调用
}
```

我们是在start()方法内部的最开始打的断点，叙述下在我这里打断点看到的结果:

+ 第一次调用时threadStatus的值是0.
+ 第二次调用时threadStatus的值不为0

查看当前线程状态的源码:

```java
// Thread.getState方法源码：
public State getState() {
    // get current thread state
    return sun.misc.VM.toThreadState(threadStatus);
}

// sun.misc.VM 源码：
public static State toThreadState(int var0) {
    if ((var0 & 4) != 0) {
        return State.RUNNABLE;
    } else if ((var0 & 1024) != 0) {
        return State.BLOCKED;
    } else if ((var0 & 16) != 0) {
        return State.WAITING;
    } else if ((var0 & 32) != 0) {
        return State.TIMED_WAITING;
    } else if ((var0 & 2) != 0) {
        return State.TERMINATED;
    } else {
        return (var0 & 1) == 0 ? State.NEW : State.RUNNABLE;
    }
}
```

所以，我们结合上面的源码可以得到引申的两个问题的结果:

> 两个问题的答案都是不可行的，在调用一次start()之后，threadStatus的值会改变(threadStatus != 0),此时再次调用start()方法会抛出IllegalThreadStateExceotion异常。
> 比如，threadStatus为2代表当前线程状态为TERMINATED.

### RUNNABLE

表示当前线程正在运行中。处于RUNNABLE状态的线程在Java虚拟机中运行，也有可能在等待其他系统资源(比如I/O).

**Java中线程的RUNNABLE状态**

看了操作系统线程的几个状态之后我们来看看Thread源码里对RUNNABLE状态的定义:

```java
/**
 * Thread state for a runnable thread.  A thread in the runnable
 * state is executing in the Java virtual machine but it may
 * be waiting for other resources from the operating system
 * such as processor.
 */
```

> Java线程的RUNNABLE状态其实是包括了传统系统线程的ready和running两个状态的。


### BLOCKED

阻塞状态。处于BLOCKED状态的线程正等待锁的释放以进入同步区。

我们用BLOCKED状态举个生活的例子:

+ Object.wait():使当前线程处于等待状态知道另一个线程唤醒它;
+ Thread.join():等待线程执行完毕,底层调用的是Object实力的wait方法;
+ LockSupport.park():除非获得调用许可，否则金庸当前线程进行线程调度。

我们延续上面的例子继续解释一下WAITING状态：

> 你等了好几分钟现在终于轮到你了，突然你们有一个“不懂事”的经理突然来了。你看到他你就有一种不祥的预感，果然，他是来找你的。
> 他把你拉到一旁叫你待会儿再吃饭，说他下午要去作报告，赶紧来找你了解一下项目的情况。你心里虽然有一万个不愿意但是你还是从食堂窗口走开了。
> 此时，假设你还是线程t2，你的经理是线程t1。虽然你此时都占有锁（窗口）了，“不速之客”来了你还是得释放掉锁。此时你t2的状态就是WAITING。然后经理t1获得锁，进入RUNNABLE状态。
> 要是经理t1不主动唤醒你t2（notify、notifyAll..），可以说你t2只能一直等待了。

我们继续延续上面的例子来解释一下TIMED_WAITING状态:

> 到了第二天中午，又到了饭点，你还是到了窗口前。
> 突然间想起你的同事叫你等他一起，他说让你等他十分钟他改个bug。
> 好吧，你说那你就等等吧，你就离开了窗口。很快十分钟过去了，你见他还没来，你想都等了这么久了还不来，那你还是先去吃饭好了。
> 这时你还是线程t1，你改bug的同事是线程t2。t2让t1等待了指定时间，t1先主动释放了锁。此时t1等待期间就属于TIMED_WATING状态。
> t1等待10分钟后，就自动唤醒，拥有了去争夺锁的资格。

### TERMINATED

终止状态。此时线程已执行完毕。

## 线程状态的转换

根据上面关于线程砖头盖的介绍我们可以得到下面的线程状态转换图:



![image-20211108225008376](D:\file\note\study-note\多线程.assets\image-20211108225008376-16363830133774.png)

我们在上面说到：处于BLOCKED状态的线程是因为在等待锁的释放。假如这里有两个线程a和b，a线程提前获得锁并且暂未释放锁，此时b就处于BLOCKED.我们先来看一个例子:

```java
public class demo9 {

    public static void main(String[] args) {
        
        Thread a = new Thread(new Runnable() {
            @Override
            public void run() {
                testMethod();
            }
        },"a");
        
        Thread b = new Thread(new Runnable() {
            @Override
            public void run() {
                testMethod();
            }
        },"b");
        
        a.start();
        b.start();
        System.out.println(a.getName()+":"+a.getState()); //输出?
        System.out.println(a.getName()+":"+b.getState()); //输出?
    }
    
    //同步方法争夺锁
    private static synchronized void testMethod(){
        try{
            Thread.sleep(2000L);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}

```

初看之下，大家可能会觉得线程a会先调用同步方法，同步方法内又调用了Thread.sleep()方法，必然会输出TIMED_WAITING,而线程b会因为等待线程a释放锁所以必然会输出BLOCKED。

其实不然，有两点需要值得大家注意，一是在测试方法blockedTest()内还有一个main线程，二是启动下次呢很难过后执行run方法还是需要消耗一定的时间的。不打断点的情况下，上面代码中都应该输出RUNNABLE。

> 测试方法的main线程只保证了a,b两个线程带哦用start()方法（转化为RUNNABLE状态），还没等两个线程真正开始争夺锁，就已经打印此时两个线程的状态(RUNNABLE)了。

这时你可能又会问了，要是我想要打印出BLOCKED状态我该怎么处理呢?其实就处理下测试方法里的main线程就可以了，你让它“休息一会儿”，打断点或者调用Thread.sleep方法就行。

这里需要注意的是main线程休息的时间，要保证在线程争夺锁的时间内，不要等到前一个线程锁都释放了你再去争夺锁，此时还是得不到BLOCKED状态的。

我们把上面的测试方法blockedTest()改动一下:

```java
public void blockedTest() throws InterruptedException {
    ······
    a.start();
    Thread.sleep(1000L); // 需要注意这里main线程休眠了1000毫秒，而testMethod()里休眠了2000毫秒
    b.start();
    System.out.println(a.getName() + ":" + a.getState()); // 输出？
    System.out.println(b.getName() + ":" + b.getState()); // 输出？
}
```

在这个例子中，由于main线程休眠，所以线程a的run()方法跟着执行，线程b再接着执行。

在线程a执行run()调用testMethod()之后，线程a休眠了2000ms（之一这里是没有释放锁的），main线程休眠完毕，接着b线程执行的时候是争夺不到锁的，所以这里输出:

```java
a:TIMED_WAITING
b:BLOCKED
```

### WATING状态与RUNNABLE状态的转换

根据转换图我们知道有3个方法可以是线程从RUNNABLE状态转为WAITING状态，我们主要介绍下Object.wait()和Thread.join()。

**Object.wait()**

> 调用wait()方法前下次呢很难过必须持有对象的锁。
> 线程调用wait()时，会释放当前的锁，知道有其它线程调用notify()/notifyAll()方法唤醒等待锁的线程。

> 需要注意的是，其它线程调用notify()方法只会唤醒单个等待锁的线程，如有有多个线程都在等待这个锁的话不一定会唤醒到之前调用wait()方法的线程。

> 同样，调用notifyAll()方法唤醒所有等待锁的线程之后，也不一定会马上把时间片分给刚才放弃锁的那个线程，需要看系统的具体调度。

**Thread.join()**

> 调用join()方法不会释放锁，会一直等待当前线程执行完毕(转换为TERMINATED状态)。

```java
public void blockedTest() {
    ······
    a.start();
    a.join();
    b.start();
    System.out.println(a.getName() + ":" + a.getState()); // 输出 TERMINATED
    System.out.println(b.getName() + ":" + b.getState());
}
```

要是没有调用join方法，main线程不管a线程是否执行完毕都会继续往下走。

a线程启动之后马上调用了join方法，这里main线程就会等待a线程执行完毕，所以这里a线程打印的状态固定是**TERMIATED**。

至于b线程的状态，有可能打印RUNNABLE(尚未进入同步方法)，也有可能打印TIMED_WAITING(进入了同步方法)。

### TIMED_WAITING与RUNNABLE状态转换

TIMED_WAITING与WAITING状态类似，只是TIMED_WAITING状态等待的时间是指定的。

**Thread.sleep(long)**

> 使当前线程睡眠指定时间。需要注意这里的“睡眠”只是暂时线程停止执行，并不会释放锁。时间到后，线程会重新进入RUNNABLE状态。

**Object.wait(long)**

> wait(long)方法使当前线程进入TIMED_WAITING状态。这里的wait(long)方法与无参方法wait()相同的地方是，都可以通过其它线程调用notify()或notifyAll()方法来唤醒。
> 不同的地方是，有参方法wait(long)就算其它线程不来唤醒它，经过指定时间long之后它会自动唤醒，拥有去争夺锁的资格。

**Thread.join(long)**

> join(long)使当前线程执行指定时间，并且使线程进入TIEMD_WAITING状态。
> 我们再来改一改刚才的示例:
> ```java
> public void blockedTest() {
    ······
    a.start();
    a.join(1000L);
    b.start();
    System.out.println(a.getName() + ":" + a.getState()); // 输出 TIEMD_WAITING
    System.out.println(b.getName() + ":" + b.getState());
}
> ```
> 这里调用a.join(1000L),因为是指定了具体a线程指定干的时间的，并且执行时间是小于a线程sleep的时间，所以a线程状态输出TIMED_WAITING。

b线程状态仍然不固定(RUNNABLE或BLOCKED)。

### 线程中断

> 在某些情况下，我们在线程启动后发现并不需要它继续执行下去时，需要中断线程。目前在Java里还没有安全直接的方法来停止线程，但是Java提供了线程中断机制来处理需要中断贤臣干的情况。
> 线程中断机制时一种协作机制。需要注意，通过中断操作并不能直接终止一个线程，而是通知需要被中断的线程自行处理。

简单介绍下Thread类里提供的关于线程中断的几个方法:

+ Thread.interrupt():中断线程。这里的中断线程并不会立即停止线程，而是设置线程的中断状态为true(默认时false)；
+ Thread.interrupted():测试当前线程是否被中断。线程的中断状态受这个方法的影响，意思是调用一次使线程中断状态设置为true,连续调用两次会使得这个线程的中断状态重新转为false;
+ Thread.isinterrupted():测试当前线程是否被中断。与上面方法不同的是调用这个方法并不会影响线程的中断状态。

> 在线程中断机制里，当其他线程通知需要被中断的线程后，线程中断的状态被设置为true，但是具体被要求中断的线程要怎么处理，完全由被中断线程自己而定，可以在合适的时机处理中断请求，也可以完全不处理继续执行下去。


# Java线程间的通信

合理地使用Java多线程可以更好地利用服务器资源。一般来讲，线程内部有自己私有的线程上下文，互不干扰。但是当我们需要多个线程之间相互协作的时候，就需要我们掌握Java线程的通信方式。

## 锁与同步

在Java中，锁的概念都是基于对象的，所以我们又经常称它为对象锁。线程和锁的关系，我们可以用婚姻关系来理解。一个锁同一时间只能被一个线程持有。也就是说，一个锁如果和一个线程“结婚”（持有），那其他线程如果需要得到这个锁，就得等这个线程和这个锁“离婚”（释放）。

在我们的线程之间，有一个同步的概念，什么是同步呢？假如我们现在有两位正在抄暑假作业答案的同学:线程A和线程B。当他们正在抄的时候，老师突然来修改了一些答案，可能A和B最后写出的暑假作业就不一样。我们为A，B能写出2本相同的暑假作业，我们就需要让老师先修改答案，然后A，B同学再抄。或者A，B同学先抄完，老师再修改答案。这就是线程A，线程B的线程同步。

可以解释为:线程同步是线程之间按照一定的顺序执行。

为了达到线程同步，我们可以使用锁来实现它。

我们先来看看一个无锁的程序:

```java
public class NoneLock {

    static class ThreadA implements Runnable {
        @Override
        public void run() {
            for (int i = 0; i < 100; i++) {
                System.out.println("Thread A " + i);
            }
        }
    }

    static class ThreadB implements Runnable {
        @Override
        public void run() {
            for (int i = 0; i < 100; i++) {
                System.out.println("Thread B " + i);
            }
        }
    }

    public static void main(String[] args) {
        new Thread(new ThreadA()).start();
        new Thread(new ThreadB()).start();
    }
}
```

执行这个程序，你会在控制台看到，线程A和线程B各自独立工作，输出自己的打印值。如下是我的电脑某一次运行的结果。每一次运行结果都会不一样。

```java
....
Thread A 48
Thread A 49
Thread B 0
Thread A 50
Thread B 1
Thread A 51
Thread A 52
....
```

那我现在有一个需求，我想等A先执行完之后，再由B去执行，怎么办呢？最简单的方式就是使用一个“对象锁”：

```java
public class demo11 {

    public static void main(String[] args) {
        new Thread(new ThreadA()).start();
        new Thread(new ThreadB()).start();
    }
    
    private static Object lock = new Object();

    static class ThreadA implements Runnable{
        @Override
        public void run() {
            synchronized (lock){
                for (int i = 0; i < 100; i++) {
                    System.out.println("Thread A " + i);
                }   
            }
        }
    }

    static class ThreadB implements Runnable{
        @Override
        public void run() {
            synchronized (lock){
                for (int i = 0; i < 100; i++) {
                    System.out.println("Thread B " + i);
                }
            }
        }
    }
}

```

这里声明了一个名字为lock的对象锁。我们在ThreadA和ThreadB内需要同步的代码块里，都是用synchronized关键字加上了同一个对象锁lock。

上文我们说到了，根据线程和锁的关系，同一时间只有一个线程持有一个锁，那么线程B就会等线程A执行完成后释放lock，线程B才能2获得锁lock。

> 这里再主线程里使用sleep方法睡眠了10毫秒，是为了防止线程B先得到锁。因为如果同时start,线程A和线程B都是处于就绪状态，操作系统可能会先让B运行。这样就会先输出B的内容，然后B执行完成之后自动释放锁，线程A再执行。

## 等待/通知机制

上面一种基于"锁"的方式，线程需要不断地去尝试获得锁，如果失败了，再继续尝试。这可能会耗费服务器资源。

而等待/通知机制是另一种方式。

Java多线程的等待/通知机制是基于`Object`类的wait()方法和notify(),notifyAll()方法来实现的。

> notify()方法会随机侥幸一个正在等待的线程，而notifyAll()会侥幸所有正在等待的线程

前面我们讲到，一个锁同一时刻只能被一个线程持有。而假如线程A现在持有了一个锁lock并开始执行，它可以使用`lock.wait()`让自己进入等待状态。这个时候，lock这个锁是被释放了的。

这时，线程B获得了lock这个锁并开始执行，它可以某一时刻，使用lock.notify(),通知之前持有lock锁并进入了等待状态的线程A，，说"线程A你不用等了，可以往下执行了"。

> 需要注意的是，这个时候线程B并没有释放锁`lock`，除非线程B这个时候使用lock.wait()释放锁，或者线程B执行结束自行释放锁，线程A才能得到lock锁。

我们用代码来实现一下:

```java
public class demo12 {

    public static void main(String[] args) {
        new Thread(new ThreadA()).start();
        new Thread(new ThreadB()).start();
    }

    private static Object lock = new Object();

    static class ThreadA implements Runnable{
        @Override
        public void run() {
            synchronized (lock){
                for (int i = 0; i < 5; i++) {
                    try {
                        System.out.println("ThreadA:" + i);
                        lock.notify();;
                        lock.wait();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
                lock.notify();
            }

        }
    }

    static class ThreadB implements Runnable{

        @Override
        public void run() {
            synchronized (lock){
                for (int i = 0; i < 5; i++) {
                    try {
                        System.out.println("ThreadB:"+i);
                        lock.notify();
                        lock.wait();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
                lock.notify();
            }
        }
    }

}

```

```
ThreadA:0
ThreadB:0
ThreadA:1
ThreadB:1
ThreadA:2
ThreadB:2
ThreadA:3
ThreadB:3
ThreadA:4
ThreadB:4
```

在这个demo里，线程A和线程B首先打印出自己需要的东西，然后使用notify()方法叫醒另一个正在等待的线程，然后自己使用wait()方法陷入等待并释放lock锁。

> 需要注意的是等待/通知机制使用的是同一个对象锁，如果你两个线程使用的是不同的对象锁，那他们之间是不能用等待/通知机制通信的。

## 信号量

JDK提供了一个类似于"信号量"功能的类`Semaphore`。但本文不是要介绍这个类，而是介绍一种基于`volatile`关键字的自己实现的信号量通信。

后面会有专门的章节介绍`volatile`,这里只是做一个简单的介绍。

> volitile关键字能够保证内存的可见性，如果用volitile关键字声明了一个变量，在一个线程里面改变了这个变量的值，那其他线程是立马可见更改后的值的。

比如我现在有一个需求，我想让线程A输出0，然后线程B输出1，再然后线程A输出2...以此类推。我应该怎样实现呢？

代码:

```java
public class demo13 {

    public static void main(String[] args) throws InterruptedException {
        new Thread(new ThreadA()).start();
        Thread.sleep(1000);
        new Thread(new ThreadB()).start();
    }

    private static volatile int signal = 0;

    static class ThreadA implements Runnable{
        @Override
        public void run() {
            while (signal < 5){
                if (signal % 2 == 0){
                    System.out.println("threadA : "+signal);
                    synchronized (this){
                        signal++;
                    }
                }
            }
        }
    }

    static class ThreadB implements Runnable{
        @Override
        public void run() {
            while (signal < 5){
                if (signal % 2 == 1){
                    System.out.println("threadB : "+signal);
                    synchronized (this){
                        signal = signal + 1;
                    }
                }
            }
        }
    }
}

```

我们可以看到，使用了一个`volatile`变量`signal`来实现了"信号量"的模型。这里需要注意的是，`volatile`变量需要进行原子操作。`signal++`并不是一个原子操作，所以我们需要使用`synchronized`给它"上锁"。

> 这种实现方式并不一定高效，本例只是演示信号量

信号量的应用场景:

假如在一个停车场中，车位是我们的公共资源。线程就如同车辆，而看门的管理员就是起的"信号量"的作用。

因为在这种场景下，多个线程(超过2个)需要相互合作，我们用简单的"锁"和"等待通知机制"就不那么方便了。这个时候就可以用到信号量。

其实JDK提供的很多多线程通信工具类都是就与信号量模型的。


## 管道

管道是基于"管道流"的通信方式。JDK提供了`PipeWriter`、`PipeReader`、`PipedOutputStream`、`PipedInputStream`。
其中，前面两个是基于字符的，后面两个是基于字节流的。

这里的实力代码使用的是基于字符的:

```java
import java.io.IOException;
import java.io.PipedReader;
import java.io.PipedWriter;

public class demo14 {


    static class ReaderThread implements Runnable{

        private PipedReader reader;

        public ReaderThread(PipedReader reader) {
            this.reader = reader;
        }

        @Override
        public void run() {
            System.out.println("this is reader");
            int receive = 0;
            try{
                while ((receive = reader.read()) != -1){
                    System.out.print((char) receive);
                }
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }

    static class WriterThread implements Runnable{

        private PipedWriter writer;

        public WriterThread(PipedWriter writer){
            this.writer = writer;
        }

        @Override
        public void run() {
            System.out.println("this is writer");
            int receive = 0;
            try {
                writer.write("test");
            } catch (IOException e) {
                e.printStackTrace();
            } finally {
                try{
                    writer.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }
    }

    public static void main(String[] args) throws IOException, InterruptedException {
        PipedWriter pipedWriter = new PipedWriter();
        PipedReader pipedReader = new PipedReader();
        pipedWriter.connect(pipedReader); //这里注意一定要连接，才能通信

        new Thread(new ReaderThread(pipedReader)).start();
        Thread.sleep(1000);
        new Thread(new WriterThread(pipedWriter)).start();
    }
}
```

我们通过线程的构造函数，传入了`PipedWrite`和`PipedReader`对象。可以简单分析一下这个示例代码的执行流程:

1. 线程ReaderThread开始执行,
2. 线程Reader使用管道reader.read()进入"阻塞",
3. 线程WriterThread开始执行，
4. 线程WriterThread用writer.write("test")往管道写入字符串，
5. 线程WriterThread使用writer.close()结束管道写入，并执行完毕,
6. 线程ReaderThread接受到管道输出的字符串并打印,
7. 线程ReaderThread执行完毕。

管道通信的应用场景:

这个很好理解。使用管道多半与I/O流相关。当我们一个线程需要另一个线程发送一个信息(比如字符串)或者文件等等时，就需要使用管道通信了。

## 其它通信相关

以上介绍了一些线程间通信的基本原理和方法。初次以外，还有一些与线程通信相关的知识点，这里一并介绍。

### join方法

join()方法是Thread类的一个实例方法。它的作用是让当前线程陷入"等待"状态，等join的这个线程执行完成后，再继续执行当前线程。

有时候，主线程创建并启动了子线程，如果子线程中需要进行大量的耗时运算，主线程往往将早于子线程结束之前结束。

如果主线程想等待子线程执行完毕后，获得子线程中的处理完的某个数据，就要用到join方法了。

示例代码；

```java
public class demo15 {

    static class ThreadA implements Runnable{

        @Override
        public void run() {
            try{
                System.out.println("我是子线程,我先睡一秒");
                Thread.sleep(1000);
                System.out.println("我是子线程，我睡了一秒");
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }

    public static void main(String[] args) throws InterruptedException {
        Thread thread = new Thread(new ThreadA());
        thread.start();
        thread.join();
        System.out.println("如果不加join方法，我会先被打出来，加了就不一样了");
    }
}

```

注意join()方法有两个重载方法，一个是join(long),一个是join(long,int)。

实际上，通过源码你会发现，join()方法及其重载方法底层都是利用了wait(long)这个方法。

对于join(long,int)，通过查看源码(JDK 1.8)发现，底层并没有精确到纳秒，而是对第二个参数做了简单的判断和处理。

### sleep方法

sleep方法是Thread类的一个静态方法。它的作用是让当前线程睡眠一段时间。它有这样两个方法:

+ Thread.sleep(long)
+ Thread.sleep(long,int)

> 同样，查看源码(JDK 1.8发现，第二个方法貌似值对第二个参数做了简单的处理，没有精确到纳秒。实际上还是调用的第一个方法。

这里需要强调的一下:sleep方法是不会释放当前的锁的，而wait方法会。这也是最常见的一个多线程面试题。

它们还有这些区别:

+ wait可以指定时间，也可以不指定;而sleep必须指定时间。
+ wait释放cpu资源，同时释放锁；sleep释放cpu资源，但是不释放锁，所以容易死锁。
+ wait必须放在同步块或同步方法中，而sleep可以在任意位置

### ThreadLocal类

ThreadLocal是一个本地线程副本变量工具类。内部是一个弱引用的Map来维护。这里不详细介绍它的原理，而是介绍它的使用，以后有独立章节来介绍ThreadLocal类的原理。

有些朋友称ThreadLocal为线程本地变量或线程本地存储。严格来说，ThreadLocal类并不属于多线程间的通信，而是让每个线程有自己"独立"的变量，线程之间互不影响。它为每个线程都创建一个副本，每个线程可以访问自己内部的副本变量。

ThreadLocal类最常用的就是set方法和get方法。示例代码:

```java
public class demo16 {

    static class ThreadA implements Runnable{

        private ThreadLocal<String> threadLocal;

        public ThreadA(ThreadLocal<String> threadLocal){
            this.threadLocal = threadLocal;
        }

        @Override
        public void run() {
            threadLocal.set("A");
            try{
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println("ThreadA输出:"+threadLocal.get());
        }
    }

    static class ThreadB implements Runnable{

        private ThreadLocal<String> threadLocal;

        public ThreadB(ThreadLocal<String> threadLocal){
            this.threadLocal = threadLocal;
        }

        @Override
        public void run() {
            threadLocal.set("B");
            try{
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println("ThreadB输出:"+threadLocal.get());
        }
    }

    public static void main(String[] args) {
        ThreadLocal<String> threadLocal = new ThreadLocal<>();
        new Thread(new ThreadA(threadLocal)).start();
        new Thread(new ThreadB(threadLocal)).start();
    }
}

```

可以看到，虽然两个线程使用的同一个ThreadLocal实例(通过构造方法传入)，但是它们各自可以存取自己当前线程的一个值。

那ThreadLocal有什么作用呢?如果只是单纯的想要线程隔离，在每个线程中声明一个私有变量就好了呀，为什么要使用ThreadLocal？

如果开发者希望将类的某个静态变量(user ID或者transaction ID)与线程状态关联，则可以考虑使用ThreadLocal。

最常见的ThreadLocal使用场景为用来解决数据库连接、session管理等。数据库连接和Session管理涉及多个复杂对象的初始化和关闭。如果在每个线程中声明一些私有变量来进行操作，那这个线程就变得不那么”轻量“了，需要频繁地创建和关闭连接。

### InheritableThreadLocal

inheritableThreadLocal类与ThreadLocal类稍有不同，inheritable是继承的意思。它不仅仅是当前线程可以存取副本值，而且它的子线程也可以存取这个副本值。





# Java内存模型基础知识

## 并发编程模型得两个关键问题

+ 线程间如何通信?即：线程之间以何种机制来交换信息
+ 线程间如何同步?即：线程以何种机制来控制不同线程间操作发生得相对顺序

有两种并发模型可以解决这两个问题:

+ 消息传递并发模型
+ 共享内存并发模型

这两种模型之间的区别如下表所示:

![img](D:\file\note\study-note\多线程.assets\两种并发模型的比较-16385170737812.png)

在Java中，使用的是共享内存并发模型。


## Java内存模型的抽象结构

### 运行时内存的划分

先谈一下运行时数据区，下面这张图相信大家一点都不陌生:

![img](D:\file\note\study-note\多线程.assets\Java运行时数据区.png)

对于每一个线程来说，栈都是私有的，而堆是共有的。

也就是说在栈中的变量(局部变量、方法定义参数、异常处理器参数)不会在线程之间共享，也就不会有内存可见性(下文会说到)的问题，也不受内存模型的影响。而在堆中的变量是共享的，本文称为共享变量。

所以，内存可见性是针对的共享变量。

### 既然堆是共享的，为什么在堆中会有内存不可见问题?

这是因为现代计算机为了高效，往往会在告诉缓存区中缓存共享变量，因为CPU访问缓存区比访问内存要快得多。

> 线程之间的共享变量存在主内存中，每个线程都有一个私有的本地内存，存储了该线程以读、写共享变量的副本。本地内存是Java内存模型的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器等。

Java线程之间的通信由Java内存模型(简称JMM)控制，从抽象的角度来说。JMM定义了线程和主内存之间的抽象关系。JMM的抽象示意图如图所示:

![image-20211205160616304](D:\file\note\study-note\多线程.assets\image-20211205160616304-16386915784562.png)

从图中可以看出:

1. 所有的共享变量都存在主内存中。
2. 每个线程都保存了一份该线程使用的共享变量的副本。
3. 如果线程A与线程B之间要通信的话，必须经历下面2个步骤:
   1. 线程A将本地内存A中跟新过的共享变量刷新到主内存中去。
   2. 线程B到主内存中去读取线程A之前已经更新过的共享变量。

所以，线程A无法直接访问线程B的工作内存，线程间通信必须经过主内存。

注意，根据JMM的规定，线程对共享变量的所有操作都必须在自己的本地内存中进行，不能直接从主内存中读取。

所以线程B并不是直接去主内存中读取共享变量的值，而是先在本地内存中找到这个共享变量，发现这个贡献变量已经被更新了，然后本地内存B去主内存中读取这个共享变量的新值，并拷贝到本地内存B中，最后线程B再读取本地内存B中的新值。

那么怎么知道这个共享变量的值被其它线程更新了呢?这就是JMM的功劳了，也是JMM存在的必要性之一。JMM通过控制主内存与每个线程的本地内存之间的交互，来提供内存可见性保证。

> Java中的volatile关键字可以保证多线程操作共享变量的可见性以及禁止指令重排序，synchronized关键字不仅保证可见性，同时也保证了原子性(互斥性)。在更底层，JMM通过内存屏障来实现内存的可见性以及禁止重排序。为了程序元的方便理解，剔除了happens-before，它更加的简单易懂，从而避免了程序员为了理解内存可见性而去学习复杂的重排序规则以及这些规则的具体实现方法。这里涉及到的所有内容后面都会有专门的章节介绍。

### JMM与Java内存区域划分的区别与联系

上面两小节分别提到了JMM和Java运行时内存区域的划分，这两者既有差别又有联系:

+ 区别
  两者是不同的概念层次。JMM是抽象的，他是用来描述一组规则，通过这个规则来控制各个变脸大哥访问方式，围绕原子性、有序性、可见性等展开的。而Java运行时内存的划分是具体的，是JVM运行Java程序时，必要的内存划分。

+ 联系
  都存在私有数据区域和共享数据区域。一般来说，JMM中的主内存属于共享数据区域，他是包含了堆和方法区;同样，JMM中的本地内存属于私有数据区域，半酣了程序计数器、本地方法栈、虚拟机栈。

实际上，他们表达的是同一种含义，这里不做区分。


# 重排序与happens-before

## 什么是重排序?

计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排。

**为什么指令重排可以提高性能？**

简单地说，每一个指令都会包含多个步骤，每个步骤可能使用不同的硬件。因此，流水线技术产生了，它的原理是指令还没有执行完，就可以开始执行指令2，而不用等到指令1执行结束之后再执行指令2，这样就大大提高了效率。

但是，流水线技术最害怕中断，恢复中断的代价是比较大的，所以我们要想办法不让流水线中断。指令重排就是减少中断的一种技术。

我们分析一下下面这个代码的执行情况:

```java
a = b + c;
d = e - f;
```

先加载b、c(注意，即有可能先加载b，也有可能先加载c)，但是再执行add(b,c)的时候，需要等待b、c装载结束才能继续执行，也就是增加了停顿，那么后面的指令也会一次有停顿，这降低了计算机的执行效率。

为了减少这个停顿，我们可以先加载e和f，然后再去加再add(b,c),这样做程序(串行)是没有影响的，但却减少了停顿。既然add(b,c)需要停顿，那还不如去做一些有意义的事情。

综上所述，指令重排对于提高CPU处理性能十分必要。虽然由此带来了乱序的问题，但是这点牺牲是值得的。

指令重排一般分为以下三种:

+ 编译器优化重排
  编译器再不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。

+ 指令并行重排
  现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性(即后一个执行的语句无需依赖前面执行的语句的结果)，处理器可以改变语句对应的机器指令的执行顺序。

+ 内存系统重排
  由于处理器使用缓存和读写缓冲区，这使得加载(load)和存储(store)操作看上去可能是在乱序执行，因为三级缓存的存在，导致内存和缓存的数据同步存在时间差。

指令重排可以保证串行语义一致，但是没有义务保证多线程间的语义也一致。所以正在多线程下，指令重排序可能会导致一些问题。

## 顺序一致性模型与JMM的保证

顺序一致性模型是一个理论参考模型，内存模型在设计的时候都会以顺序一致性内存模型作为参考。

### 数据竞争与顺序一致性

当程序未正确同步的时候，就可能存在数据竞争

> 数据竞争：在一个线程中写一个变量，在另一个线程读同一个变量，并且写和读没有通过同步来序。

如果程序中包含了数据竞争，那么运行的结果往往充满了不确定性，比如读发生了在了写之前，可能就会读到错误的值，如果一个线程程序能够正确同步，那么就不存在数据竞争。

Java内存模型(JMM)对于正确同步多线程程序的内存一致性做了以下保证:

> 如果程序是正确同步的，程序的执行将具有顺序一致性。及程序的执行结果和该程序在顺序一致性模型中执行的结果相同。

这里的同步包括了使用volatile、final、synchronized等关键字来实现多线程下的同步。

如果程序员没有正确使用`volatile`、`final`、`synchronized`，那么即便是是同了同步(单线程下的同步)，JMM也不会有内存可见性的保证，可能会导致你的程序出错，并且具有不可重现性，很难排查。

所以如何正确使用volatile、final、synchronized，是程序员应该去了解的。后面会右转你们的章节介绍这几个关键字的内存语义及使用。

### 顺序一致性模型

顺序一致性模型是一个理想化的理论参考模型，它为程序员提供了极强的内存可见性保证。

顺序一致性模型有两大特性:

+ 一个线程中的所有操作必须按照程序的顺序(即Java代码的顺序)来执行。
+ 不管程序是否同步，所有线程都只能看到一个单一的操作执行顺序。即在顺序一致性模型中，每个操作必须是原子性的，且立刻对所有线程可见。

为了理解这两个特性，我们举个例子，假设有两个线程A和B并行执行，线程A有3个操作，它们程序中的顺序是A1 > A2 > A3,线程B也有3个操作，B1 > B2 > B3。

假设正确使用了同步，A线程的3个操作执行后释放锁，B线程获取同一个锁。那么在顺序一致性模型中的执行效果如下所示:

![img](D:\file\note\study-note\多线程.assets\assets%2F-L_5HvtIhTFW9TQlOF8e%2F-L_5TIKcBFHWPtY3OwUo%2F-L_5TIqcRdKDsOukyesb%2F正确同步-16389475377381.png)

操作的执行整体上有序，并且两个线程都只能看到这个执行顺序。

假设没有使用同步，那么在顺序一致性模型中的执行效果如下所示:

![img](D:\file\note\study-note\多线程.assets\assets%2F-L_5HvtIhTFW9TQlOF8e%2F-L_5TIKcBFHWPtY3OwUo%2F-L_5TIqeL6b2dOSGAIEt%2F没有正确同步.png)


操作的执行整体上无序，但是两个线程都只能看到这个执行顺序。之所以可以得到这个保证，是因为顺序一致性模型中的每个操作必须立即对任意线程可见。

但是JMM没有这样的保证。

比如，在当前线程把写过的数据缓存在本地内存中，在没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观察，这个写操作根本没有被当前线程所执行。只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才对其它线程可见。在这种情况下，当前线程和其它线程看到的执行顺序是不一样的。

### JMM中同步程序的顺序一致性效果

在顺序一致性模型中，所有操作完全按照程序的顺序串行执行。但是JMM中，临界区(同步块或同步方法中)的代码可以发生重排序（但不允许临界区内的代码"逃逸"到临界区外，因为会破坏锁的内存语义）。

虽然线程A在临界区做了重排序，但是因为锁的额特性，线程B无法观察到线程A在临界区的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。

同时，JMM会在退出临界区和进入临界区做特殊的处理，使得在临界区内程序获得与顺序一致性模型相同的内存视图。

由此可见，JMM的具体实现方针是:在不改变(正确同步的)程序执行结果的前提下，尽量为编译器和处理器的优化打开方便之门。

### JMM中未同步程序的顺序一致性效果

对于未同步的多线程程序，JMM只提供最小安全性:线程读取到的值，要么是之前某个线程写入的值，要么是默认值，不会无中生有。

为了实现这个安全性，JVM在堆上分配对象时，首先会对内存空间清零，然后才会在上面分配对象(这两个操作是同步的)。

JMM没有保证未同步程序的执行结果与该程序在顺序一致性中执行结果一致。因为如果要保证执行结果一致，那么JMM需要禁止大量的优化，对程序的执行性能会产生很大的影响。

未同步程序在JMM和顺序一致性内存模型中的执行特性有以下差异:

1. 顺序一致性保证单线程内的操作会按程序的顺序执行；JMM不保证单线程内的操作会按程序的顺序执行。(因为重排序，但是JMM保证单线程下的重排序不影响执行结果)
2. 顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而JMM不保证所有线程能看到一致性的操作执行顺序。（因为JMM不保证所有操作立即可见）
3. JMM不保证对64位的long型和double型变量的写操作具有原子性，而顺序一致性模型保证对所有的内存读写操作都具有原子性。

## happens-before

### 什么是happens-before?

一方面，程序员需要JMM提供一个强的内存模型来编写代码；另一方面，编译器和处理器希望JMM对它们的束缚越少越好，这样它们就可以最可能多的做优化来提高性能，希望的是一个弱的内存模型。

JMM考虑了这两种需求，并且找到了平衡点，对编译器和处理器来说，只要不改变程序的执行结果(单线程程序和正确同步了的多线程程序)，编译器和处理器怎么优化都行。

而对于程序员，JMM提供了happens-before规则（JSR-133规范），满足了程序员的需求--简单易懂，并且提供了足够强的内存可见性保证。换言之，程序员只要遵循happens-before规则，那他写的程序就能保证在JMM中具有强的内存可见性。

JMM使用happens-before关系的定义如下:

1. 如果一个操作happpens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。
2. 两个操作之间存在happens-before关系，并不意味这Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么JMM也允许这样的重排序。

happens-before关系本质上和as-if-serial语义是一回事。

as-if-serial语义保证单线程内重排序后的执行结果和程序代码本身应有的结果是一致的，happens-before关系保证正确同步的多线程程序的执行结果不被重排序改变。

总之，如果操作A happens-before 操作B，那么操作A在内存上所做的操作对操作B都是可见的，不管它们在不在一个线程。

### 天然的happens-before关系

在Java中，有以下天然的happpens-before关系:

+ 程序顺序规则:一个线程的每一个操作，happens-before于该线程中的任意后续操作。
+ 监视器锁规则:对一个锁的解锁，happens-before于随后对这个锁的加锁。
+ colatile变量规则:对一个volatile域的写，happens-before于任意后续对这个volatile域的读。
+ 传递性:如果A happens-before B,且B happens-before C,那么A happens-before C。
+ start规则:如果线程A执行操作ThreadB.start()启动线程B，那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作
+ join规则:如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。

举例:

```
int a = 1; // A操作
int b = 2; // B操作
int sum = a + b;// C 操作
System.out.println(sum);
```

根据以上介绍的happens-before规则，假如只有一个线程，那么不难得出：

```
1> A happens-before B 
2> B happens-before C 
3> A happens-before C
```

注意，真正在执行指令的时候，其实JVM有可能对操作A&B进行重排序，因为无论先执行A还是B，它们都对对方是可见的，并且不影响执行结果。

如果这里发生了重排序，这在视觉上违背了happens-before原则，但是JMM是允许这样的重排序的。

所以，我们只关心happens-before规则，不用关心JVM到底是怎样执行的。只要确定操作A happpens-before操作B就行了。

重排序有两类，JMM对这两类重排序有不同的策略:

+ 会改变程序执行结果的重排序，比如A -> c,JMM要求编译器和处理都不允许这种重排序。
+ 不会改变程序执行结果的重排序，比如A -> B,JMM对编译器和处理不做要求，允许这种重排序。


# volatitle

## 几个基本概念

### 内存可见性

在Java内存模型那一章我们介绍了JMM有一个主内存，每个线程有自己私有的工作内存，工作内存中保存了一些变量在主内存的拷贝。

内存可见性，指的是线程之间的可见性，当一个线程修改了共享变量时，另一个线程可以读取到这个修改后的值。

### 重排序

为优化程序性能，对原有的指令执行顺序进行优化重新排序。重排序可能发生在多个阶段，比如编译重排序、CPU重排序等。

### happens-before原则

是一个给程序员使用的规则，只要程序员在写代码的时候遵循happens-before规则，JVM就能保证指令在多线程之间的顺序性符合程序员的预期

## volatile的内存语义

在Java中，volatile关键字有特殊的内存语义。volatile主要有以下两个功能:

+ 保证变量的内存可见性
+ 禁止volatile变量与普通变量重排序(JSR133提出，Java 5 开始才有这个“增强的volatile内存语义”)

### 内存可见性

以一段实例代码开始:

```java
public class VolatileExample {
    int a = 0;
    volatile boolean flag = false;

    public void writer() {
        a = 1; // step 1
        flag = true; // step 2
    }

    public void reader() {
        if (flag) { // step 3
            System.out.println(a); // step 4
        }
    }
}
```

在这段代码里，我们使用`volatile`关键字修饰了一个boolean类型的变量flag。

所谓内存可见性，指的是当一个线程对volatile修饰的变量进行写操作(比如step2)时，JMM会立即把该线程对应的本地内存中的共享变量的值刷新到主内存中；当一个线程对`volatile`修饰的变量进行读操作(比如step3)时，JMM会把立即把该线程对应的本地内存置为无效，从主内存中读取共享变量的值。

> 在这一点上，volatile与锁具有相同的内存效果，volatile变量的写和锁的释放具有相同的内存语义，volatile变量的读和锁的获取具有相同的内存语义。

假设在时间线上，线程A先自行方法writer方法，线程B后执行reader方法。那必然会有下图:

而如果flag变量没有用volatile修饰，在step2,线程A的本地内存里面的变量就不会立即更新到主内存，那随后线程B也同样不会去主内存拿最新的值，仍然使用线程B本地内存缓存的变量的值a = 0,flag = false。

### 禁止重排序

在JSR-133之前的旧的Java内存模型中，是允许volatile变量与普通变量重排序的。那上面的案例中，可能就会被重排序成下列时序来执行:

1. 线程A写volatile变量，step 2，设置flag为true；
2. 线程B读同一个volatile,step 3，读取到flag为true；
3. 线程B读普通变量，step 4,读取到 a = 0;
4. 线程A修改普通变量，step 1，设置 a = 1;

可见，如果volatile变量与普通变量发生了重排序，虽然volatile变量能保证内存可见性，也可能导致普通变量读取错误。

所以在旧的内存模型中，volatile的写-读就不能与锁的释放-获取具有相同的内存语义了。为了提供一种比锁更轻量级的线程间的通信机制，JSR-133专家组决定增强volatile的内存语义:严格限制编译器和处理器对volatile变量与普通变量的重排序。

编译器还好说，JVM是怎么还能限制处理器的重排序呢？它是通过内存屏障来实现的。

什么是内存屏障?硬件层面，内存屏障分两种：读屏障(Load Barrier)和写屏障(Store Barrier)。内存屏障有两个作用：

1. 阻止屏障两侧的指令重排序;
2. 强制把写缓冲区/高速缓冲中的脏数据等写回主内存，或者让缓存中相应的数据失效。

> 注意这里的缓存主要指的是CPU缓存，如L1,L2等

编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。编译器选择了一个比较保守的JMM内存屏障插入策略，这样可以保证在任何处理器平台，任何程序中都能得到正确的volatile内存语义。这个策略是:

+ 在每个volatile写操作前插入一个StoreStore屏障;
+ 在每个volatile写操作后插入一个StoreLoad屏障;
+ 在每个volatile读操作前插入一个LoadLoad屏障;
+ 在每个volatile读操作后再插入一个LoadStore屏障

> 再逐个解释这几个屏障。注:下述Load代表读操作，Store代表写操作
> LoadLoad屏障:对于这样的语句Load1;LoadLoad;Load2,在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。
> StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。
> LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。
> StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的（冲刷写缓冲器，清空无效化队列）。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能

对于连续多个volatile变量读或者连续多个volatile变量写，编译器做了一定的优化来提高性能，比如:

> 第一个volatile读;
> LoadLoad屏障；
> 第二个volatile读；
> LoadStore屏障

再介绍一下volatile与普通变量的重排序规则:

1. 如果第一个操作是volatile读，那无论第二个操作是什么，都不能重排序；
2. 如果第二个操作是volatile写，那无论第一个操作是什么，都不能重排序；
3. 如果第一个操作是volatile写，第二个操作是volatile读，那不能重排序。

举个例子，我们在案例中step 1，是普通变量的写，step 2是volatile变量的写，那符合第2个规则，这两个steps不能重排序。而step 3是volatile变量读，step 4是普通变量读，符合第1个规则，同样不能重排序。
但如果是下列情况：第一个操作是普通变量读，第二个操作是volatile变量读，那是可以重排序的：

```java
// 声明变量
int a = 0; // 声明普通变量
volatile boolean flag = false; // 声明volatile变量

// 以下两个变量的读操作是可以重排序的
int i = a; // 普通变量读
boolean j = flag; // volatile变量读
```

## volatile的用途

从volatile的内存语义来看，volatile可以保证内存可见性且禁止重排序。

在保证内存可见性这一点上，volatile有着与锁相同的内存语义，所以可以作为一个"轻量级"的锁来使用。但由于volatile仅仅保证对单个volatile变量的读/写具有原子性，而锁可以保证整个临界区代码的执行具有原子性。所以在功能上，锁比volatile更强大;在性能上，volatile更有优势。

在禁止重排序这一点上，volatile也是非常有用的。比如我们熟悉的单例模式，其中有一种实现方式是"双重锁检查"，比如这样的代码:

```java
public class Singleton {

    private static Singleton instance; // 不使用volatile关键字

    // 双重锁检验
    public static Singleton getInstance() {
        if (instance == null) { // 第7行
            synchronized (Singleton.class) {
                if (instance == null) {
                    instance = new Singleton(); // 第10行
                }
            }
        }
        return instance;
    }
}
```

如果这里的变量声明不使用volatile关键字，是可能会发生错误的。它可能会被重排序:

```java
instance = new Singleton(); // 第10行

// 可以分解为以下三个步骤
1 memory=allocate();// 分配内存 相当于c的malloc
2 ctorInstanc(memory) //初始化对象
3 s=memory //设置s指向刚分配的地址

// 上述三个步骤可能会被重排序为 1-3-2，也就是：
1 memory=allocate();// 分配内存 相当于c的malloc
3 s=memory //设置s指向刚分配的地址
2 ctorInstanc(memory) //初始化对象
```

而一旦假设发生了这样的重排序，比如线程A在第10行执行了步骤1和步骤3，但是步骤2还没有执行完。这个时候线程A执行到了第7行，它会判定instance不为空，然后直接返回了一个未初始化完成的instance！
所以JSR-133对volatile做了增强后，volatile的禁止重排序功能还是非常有用的。


# synchronized与锁

这篇文章我们来聊一聊Java多线程里面的"锁"。

首先需要明确的一点是:Java多线程的锁都是基于对象的，Java中的每一个对象都可以作为一个锁。

还有一点需要注意的是，我们常听到的类锁其实也是对象锁。

Java类只有一个Class对象(可以有多个实例对象，多个实例共享这个Class对象)，而Class对象也是特殊的Java对象。所以我们常说的类锁，其实就是Class对象的锁。

## Synchronized关键字

说到锁，我们通常会谈到synchronized这个关键字。它翻译成中文就是"同步"的意思。

我们通常使用`synchronized`关键字来给一段代码或一个方法上锁。它通常有以下三种形式:

```java
//关键字在实例方法上，锁为当前实例
public synchronized void instanceLock(){
    // code
}

//关键字在静态方法上，锁为当前Class对象
public static synchronized void classLock(){
    // code
}

//关键字在代码块上，锁为括号里面的对象
public void blockLock(){
    Object o = new Object();
    synchronized(o){
        //code
    }
}
```

我们这里介绍一下"临界区"的概念。所谓"临界区"，指的是某一块代码区域，它同一时刻只能由一个线程执行。在上面的例子中，如果`synchronized`关键字在方法上，那临界区就是整个方法方法内部。而如果是使用synchronized代码块，那临界区就指的是代码块内部的区域。

通过上面的例子我们可以看到，下面这两个写法其实就是等价的作用:

```java
// 关键字在实例方法上，锁为当前实例
public synchronized void instanceLock() {
    // code
}

// 关键字在代码块上，锁为括号里面的对象
public void blockLock() {
    synchronized (this) {
        // code
    }
}
```

同理，下面这两个方法也应该是等价的:

```java
// 关键字在静态方法上，锁为当前Class对象
public static synchronized void classLock() {
    // code
}

// 关键字在代码块上，锁为括号里面的对象
public void blockLock() {
    synchronized (this.getClass()) {
        // code
    }
}
```

## 几种锁

Java 6为了减少获得锁和释放锁带来的性能消耗，引入了"偏向锁"和"轻量级锁"。在Java6以前，所有的锁都是"重量级"锁。所以在Java6及其以后，一个对象其实有四种锁的状态，它们分别由低到高依次是:

1. 无锁状态
2. 偏向锁状态
3. 轻量级锁状态
4. 重量级锁状态

无锁就是没有对资源进行锁定，任何线程都可以尝试去修改它，无锁在这里不细讲。。

几种锁会随着竞争情况逐渐升级，锁的升级很容易发生，但是锁降级发生的条件会比较苛刻，锁降级发生在Stop The World期间，当JVM进入安全点的时候，会检查是否有闲置的锁，然后进行降级。

> 关于锁降级有两点说明：
> 1. 不同于大部分文章说锁不能降级，实际上HotSpot JVM是支持锁降级的，文末有链接。
> 2. 上面提到的Stop The World期间，以及安全点，这是知识是属于JVM的知识范畴，本文不做细讲。

下面分别介绍这几种锁以及它们之间的升级。

### Java对象头

前面我们提到，Java的锁都是基于对象的。首先我们看一个对象的"锁"的信息是存放在什么地方的。

每个Java对象都有对象头。如果是非数组类型，则用2个字宽来存储对象头，如果是数组，则会用3个字宽来存储对象头。在32位处理器中，一个字宽是32位；在64位虚拟机中，一个字宽是64位。对象头的内容如下表:

| 长度     | 内容                   | 说明                         |
| -------- | ---------------------- | ---------------------------- |
| 32/64bit | Mark Word              | 存储对象的hashCode或锁信息等 |
| 32/64bit | Class Metadata Address | 存储到对象类型数据的指针     |
| 32/64bit | Array length           | 数组的长度（如果是数组）     |

我们主要来看看

| 锁状态   | 29 bit 或 61 bit             | 1 bit 是否是偏向锁？       | 2 bit 锁标志位 |
| -------- | ---------------------------- | -------------------------- | -------------- |
| 无锁     |                              | 0                          | 01             |
| 偏向锁   | 线程ID                       | 1                          | 01             |
| 轻量级锁 | 指向栈中锁记录的指针         | 此时这一位不用于标识偏向锁 | 00             |
| 重量级锁 | 指向互斥量（重量级锁）的指针 | 此时这一位不用于标识偏向锁 | 10             |
| GC标记   |                              | 此时这一位不用于标识偏向锁 | 11             |

可以看到，当对象状态为偏向锁时，`Mark Word`存储的是偏向的线程ID；当状态为轻量级锁时，`Mark Word`存储的是指向线程栈中的`Lock Record`的指针;当状态为重量级锁时，`Mark Word`为指向堆中的monitor对象的指针。

### 偏向锁

Hotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一个线程多次获得，于是引入了偏向锁。

偏向锁会偏向第一个访问的线程，如果在接下来的运行过程中，该锁没有被其他的线程访问，则持有偏向锁的线程将永远不需要触发访问。也就是说，偏向锁在资源无竞争情况下消除了同步语句，连CAS操作都不做了，提高了程序的运行性能

> 大白话就是对锁置个变量，如果发现为true，代表资源无竞争，则无需再走各种加锁/解锁流程。如果为false，代表存在其它线程竞争资源，那么就会走后面的流程。

**实现原理**

一个线程在第一次进入同步块时，会在对象头和栈帧中的锁记录里存储锁的偏向的线程ID。当下次该线程进入这个同步块时，会去检查锁的Mark Word里面是不是放的自己线程ID。

如果是，表明线程已经获得了锁，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁;如果不是，就代表有另一个线程来竞争这个偏向锁。这个时候会尝试使用CAS来替换Mark Word里面的线程ID为新线程的ID，这个时候要分两种情况；

+ 成功，表示之前的线程不存在了，Mark Word里面的线程ID为新线程的ID，锁不会升级，仍然为偏向锁;
+ 失败，表示之前的线程仍然存在，那么暂停之前的线程，设置偏向锁表示为0，并设置锁标志位为00，升级为轻量级锁，会按照轻量级锁的方式进行竞争锁。

> CAS:Compare and Swap
> 比较并设置。用于在硬件层面上提供原子性操作。在Intel处理中，比较并交换通过指令cmpxchg实现。比较是否和给定的数值一致，如果一致则修改，不一致则不修改。

线程竞争偏向锁的过程如下:

![img](D:\file\note\study-note\多线程.assets\assets%2F-L_5HvtIhTFW9TQlOF8e%2F-L_5TIKcBFHWPtY3OwUo%2F-L_5TJcrxgO7BhuMHkor%2F偏向锁2-16390161139292.jpg)

图中涉及到了lock record指针指向当前堆栈中的最近一个lock record，是轻量级锁按照先来先服务的模式进行了轻量级锁的加锁。

**撤销偏向锁**

偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。

偏向锁升级成轻量级锁时，会暂停拥有偏向锁的线程，重置偏向锁的标识，这个过程看起来容易，实则开销还是很大的，大概的过程如下:

1. 在一个安全点(在这个时间点上没有字节码正在执行)停止拥有锁的线程。
2. 遍历线程栈，如果存在锁记录的话，需要修复锁记录和Mark Word，使其变成无锁状态。
3. 唤醒被停止的线程，将当前锁升级成轻量级锁。

所以，如果应用程序里所有的锁通常处于竞争状态，那么偏向锁就会是一种累赘，对于这种情况，我们可以一开始就把偏向锁这个默认功能给关闭：

```java
-XX:UseBiasedLocking=false。
```

下面这个图总结了偏向锁的获得和撤销；

![img](D:\file\note\study-note\多线程.assets\assets%2F-L_5HvtIhTFW9TQlOF8e%2F-L_5TIKcBFHWPtY3OwUo%2F-L_5TJctbmT4TYol6GFi%2F偏向锁-16390168805774.png)

### 轻量级锁

多个线程在不同时段获取同一把锁，即不存在锁竞争的情况，也就没有线程阻塞。针对这种情况，JVM采用轻量级锁来避免线程的阻塞与唤醒。

**轻量级锁的加锁**

JVM会为每个线程在当前线程的栈帧中创建用于存储锁记录的空间，我们称为Dispalced Mark Word。如果一个线程获得锁的时候发现是轻量级锁，会把锁的Mark Word复制到自己的Displaced Mark Word里面。

然后线程尝试用CAS将锁的Mark Word替换为指向锁记录的。如果成功，当前线程获得锁，如果失败，表示Mark Word已经替换成了其它线程的锁记录，说明在与其它线程竞争锁，当前线程就尝试使用自旋来获取锁。

> 自旋：不断尝试去获取锁，一般用循环来实现。

自旋是需要消耗CPU的，如果一直获取不到锁的话，那该线程就一直处在自旋状态，白白浪费CPU资源。解决这个问题最简单的方法就是指定自旋的次数，例如让其循环10次，如果还没获取到锁就进入阻塞状态。

但是JDK采用了更聪明的方式--适应性自旋，简单来说就是线程如果自旋成功了，则下次自旋的次数会更多，如果自旋失败了，则自旋的次数就会减少。

自旋也不是一直进行下去的，如果自旋到一定程序(和JVM、操作系统相关)，依然没有获取到锁，称为自旋失败，那么这个线程会阻塞。同时这个锁就会升级成重量级锁。

**轻量级锁的释放**

在释放锁时，当前线程会使用CAS操作将Displaced Mark Word的内容复制回锁的Mark Word里面，如果没有发生竞争，那么这个复制的操作会成功。如果有其它线程因为自旋多次导致轻量级锁升级成了重量级锁，那么CAS操作会失败，此时会释放锁并唤醒被阻塞的线程。

一张图说明加锁和释放锁的过程:

![image-20211209105552479](D:\file\note\study-note\多线程.assets\image-20211209105552479-16390185538107.png)

### 重量级锁

重量级锁依赖于操作系统的互斥量(mutex)实现的，而操作系统中线程间状态的转换需要相对比较长的时间，所以重量级锁效率很低，但被阻塞的线程不会消耗CPU。

前面说到，每一个对象都可以当作一个锁，当多个线程同时请求某个对象锁时，对象锁会设置几种状态用来区分请求的线程:

```
Contention List：所有请求锁的线程将被首先放置到该竞争队列
Entry List：Contention List中那些有资格成为候选人的线程被移到Entry List
Wait Set：那些调用wait方法被阻塞的线程被放置到Wait Set
OnDeck：任何时刻最多只能有一个线程正在竞争锁，该线程称为OnDeck
Owner：获得锁的线程称为Owner
!Owner：释放锁的线程
```

当一个线程尝试获得锁时，如果该锁已经被占用，则会将该线程封装成一个`ObjectWaiter`对象插入到Contention List的队列的队首，然后调用`park`函数挂起当前线程。

当线程释放锁时，会从Contention List或EntryList中挑选一个线程唤醒，被选中的线程叫做`Heirpresumptive`即假定继承人，假定继承人被唤醒后会尝试去获得锁，但`synchronized`是非公平的，所以假定继承人不一定能获得锁。这是因为对于重量级锁，线程先自旋尝试获得锁，这样做的目的是为了减少执行操作系统同步操作带来的开销。如果自旋不成功再进入等待队列。这对那些已经再等待队列中的线程来说，稍微显得不公平，还有一个不公平的地方是自旋线程可能会抢占了Ready线程的锁。


当线程获得锁后调用`Object.wait`方法，则会将线程加入到WaitSet中，当被Object，notify唤醒后，会将线程从WaitSet移动到Contention List或EntryList中去。需要注意的是，当调用一个锁对象的`wait`或`notify`方法时，如当前锁的状态时偏向锁或轻量级锁则会先膨胀成重量级锁。

### 总结锁的升级流程

每一个线程在准备获取共享资源时:

第一步，检查Mark Word里面是不是放的自己的ThreadId,如果是，表示当前线程是处于“偏向锁”。

第二步，如果Mark Word不是自己的ThreadId,锁升级，这时候，用CAS来执行切换，新的线程根据MarkWord里面现有的ThreadId,通知之前线程暂停，之前线程将MarkWord的内容置为空。

第三步，两个线程都把锁对象的HashCode复制到自己新建的用于存储锁的记录空间，接着开始通过CAS操作，把锁对象的Mark Word的内容修改为自己新建的记录空间的地址的方式竞争MarkWord。

第四步，第三步中成功执行CAS的获得资源，失败的则进入自旋。

第五步，自旋的线程在自旋过程中，成功获得资源(即之前获得的资源的线程执行完并释放了共享资源)，则整个状态依然处于轻量级锁的状态，如果自旋失败。

第六步，进入重量级锁的状态，这个时候，自旋的线程进入阻塞，等待之前线程执行完成并唤醒自己。

### 各种锁的优缺点对比

| 锁       | 优点                                                         | 缺点                                             | 适用场景                             |
| -------- | ------------------------------------------------------------ | ------------------------------------------------ | ------------------------------------ |
| 偏向锁   | 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。 | 如果线程间存在锁竞争，会带来额外的锁撤销的消耗。 | 适用于只有一个线程访问同步块场景。   |
| 轻量级锁 | 竞争的线程不会阻塞，提高了程序的响应速度。                   | 如果始终得不到锁竞争的线程使用自旋会消耗CPU。    | 追求响应时间。同步块执行速度非常快。 |
| 重量级锁 | 线程竞争不使用自旋，不会消耗CPU。                            | 线程阻塞，响应时间缓慢。                         | 追求吞吐量。同步块执行速度较长。     |


# CAS与原子操作

## 乐观锁与悲观锁的概念

锁可以从不同的角度分类。其中，乐观锁和悲观锁是一种分类方式。

**悲观锁:**

悲观锁就是我们常说的锁。对于悲观锁来说，它总是认为每次访问共享资源时会发生冲突，所以必须对每次数据操作加上锁，以保证临界区的程序同一时间只能有一个线程在执行。

**乐观锁:**

乐观锁又称为"无锁"，顾名思义，它只是乐观派。乐观派总是假设对共享资源的访问没有冲突，线程可以不停地执行，无需加锁也无需等待。而一旦多个线程发生冲突，乐观锁通常是使用一种称为CAS的技术来保证线程执行的安全性。

由于无锁操作中没有锁的存在，因此不可能出现死锁的情况，也就是说**乐观锁天生免疫死锁**

乐观锁多用于“读多写少”的环境，避免频繁加锁影响性能；而悲观锁多用于"写多读少"的环境，避免频繁失败和重试影响性能。

## CAS的概念

CAS的全称是:比较并交换(Compare And Swap)。在CAS中，有这样三个值:

+ V:要更新的变量(var)
+ E:预期值
+ N:新值

比较并交换的过程如下:

判断V是否等于E，如果等于，将V的值设置为N；如果不等，说明已经有其它线程更新了V，则当前线程放弃更新，什么都不做。

所以这里的预期值E本质上指的是"旧值"。

我们以一个简单的例子来解释这个过程:

1. 如果有一个多线程共享的变量i原本等于5，我现在在线程A中，想把它设置为新的值6;
2. 我们使用CAS来做这个事情;
3. 首先我们用i去与5对比，发现它等于5，说明没有被其它线程改过，那我就把他设置为新的值6，此次CAS成功，i的值被设置成了6；
4. 如果不等于5，说明i被其它线程改过了(比如现在i的值为2)，那么我就什么都不做，此次CAS失败，i的值仍然为2.

在这个例子中，i就是V，5就是E，6就是N。

那有没有可能我在判断了i为5之后，正准备更新它的新值的时候，被其他线程更改了i的值呢？

不会的。因为CAS是一种原子操作，它是一种系统原语，是一条CPU的原子指令，从CPU层面保证它的原子性

当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。

## Java实现CAS的原理 - Unsafe类

前面提到，CAS是一个原子操作，那么Java是怎样来使用CAS的呢?我们知道，在Java中，如果一个方法是native，那Java就不负责具体实现它，而是交给底层的JVM使用c或者c++去实现。

在Java中，有一个Unsafe类，它在`sun.misc`包中。它里面是一些native方法，其中就有几个关于CAS的:

```java
boolean compareAndSwapObject(Object o, long offset,Object expected, Object x);
boolean compareAndSwapInt(Object o, long offset,int expected,int x);
boolean compareAndSwapLong(Object o, long offset,long expected,long x);
```

当然，它们都是`public native`的。

Unsafe中对CAS的实现是C++写的，它的具体实现和操作系统、CPU都有关系。

Linux的X86下主要是通过`cmpxchgl`这个指令在CPU级完成CAS操作的，但在多处理器情况下必须使用`lock`指令加锁来完成。当然不同的操作系统和处理器的实现会有所不同，大家可以自行了解。

当然，Unsafef类里面还有其它方法用于不同的用途。比如支持线程挂起和恢复的park和unpack,LockSupport类底层就是调用了这两个方法。还有支持反射操作的allocateInstance()方法。

## 原子操作-AtomicInteger类源码分析

上面介绍了Unsafe类的几个支持CAS的方法。那Java具体是如何使用这几个方法来实现原子操作的呢?

JDK提供了一些用于原子操作的类，在Java.util.concurrent.atomic包下面。在JDK11中，有如下17个类:

![img](D:\file\note\study-note\多线程.assets\assets%2F-L_5HvtIhTFW9TQlOF8e%2F-L_5TIKcBFHWPtY3OwUo%2F-L_5TJH5r93uLYB5jEEg%2F原子类-16390325912979.jpg)

从名字就可以看出来这些类大概的用途

+ 原子更新基本类型
+ 原子更新数组
+ 原子更新引用
+ 原子更新字段(属性)

这里为我们以AtomicInteger类的getAndAdd(int delta)方法为例，来看看Java是如何实现原子操作的。

先看看这个方法的源码:

```java
public final int getAndAdd(int delta) {
    return U.getAndAddInt(this, VALUE, delta);
}
```

这里的U其实就是一个Unsafe对象:

```java
private static final jdk.internal.misc.Unsafe U = jdk.internal.misc.Unsafe.getUnsafe();
```

所以其实`AtomicInteger`类的`getAndAdd(int delta)`方法就是调用`unsafe`类的方法来实现的：

```java
@HotSpotIntrinsicCandidate
public final int getAndAddInt(Object o, long offset, int delta) {
    int v;
    do {
        v = getIntVolatile(o, offset);
    } while (!weakCompareAndSetInt(o, offset, v, v + delta));
    return v;
}
```

我们来一步步解析这段源码。首先，对象o是this,也就是一个`AtomicInteger`对象然后`offset`是一个常量value。这个常量是在`AtomicIntegere`类中声明的:

```java
private static final long VALUE = U.objectFieldOffset(AtomicInteger.class, "value");
```

同样是调用的`Unsafe`的方法。从方法名字上来看，是得到了一个对象字段偏移量。

> 用于获取某个字段相对Java对象的"起始地址"的偏移量。
> 一个Java对象可以看成是一段内存，各个字段都得按照一定的顺序放在这段内存里，同时考虑到对齐要求，可能这些字段不是连续放置的，
> 用这个方法能准确地告诉你某个字段相对于对象的其实内存地址的字节偏移量，因为是相对偏移量，所以它其实跟某某个具体对象又没什么太大关系，跟class的定义和虚拟机的内存模型的实现细节更相关。

继续看源码。前面我们讲到，CAS是"无锁"的基础，它允许更新失败。所以经常会与while循环搭配，在失败后不断去重试。

这里声明一个v，也就是要返回的值。从`getAndAddInt`来看，它返回的应该是原来的值，而新的值的`v+delta`。

这里使用的是do-while循环。这种循环不多见，它的目的是保证循环体内的语句至少会被执行一遍。这样保证才能保证return的值v是我们期待的值。

循环体的条件是一个CAS方法:

```java
public final boolean weakCompareAndSetInt(Object o, long offset,
                                          int expected,
                                          int x) {
    return compareAndSetInt(o, offset, expected, x);
}

public final native boolean compareAndSetInt(Object o, long offset,
                                             int expected,
                                             int x);
```

可以看到，最终其实是调用的我们之前说到了CAS`native`方法。那为什么要经过一层`weakCompareAndSetInt`呢?从JDK源码上看不出来什么。在JDK 8及之前的版本，这两个方法是一样的。

> 而在JDK 9开始，这两个方法上面增加了@HotSpotIntrinsicCandidate注解。这个注解允许HotSpot VM自己来写汇编或IR编译器来实现该方法以提供性能。也就是说虽然外面看到的在JDK9中weakCompareAndSet和compareAndSet底层依旧是调用了一样的代码，但是不排除HotSpot VM会手动来实现weakCompareAndSet真正含义的功能的可能性。

根据本文第一篇参考文章，它跟volatile有关。

简单来说，`weakCompareAndSet`操作仅保留了`volatile`自身变量的特性，而除去了happens-before规则带来的内存语义。也就是说，`weakCompareAndSet`无法保证处理操作目标的volatile变量外的其它变量的执行顺序(编译器和处理器为了优化程序性能而对指令序列进行重新排序)，同时也无法保证这些变量的可见性。这在一定程度上可以提高性能。

再回到循环条件上来，可以看到它是在不断尝试去用CAS更新。如果更新失败，就继续重试。那为什么要把获取"旧值"v的操作放到循环体内呢？其实这也很好理解。前面我们说了，CAS如果旧值V不等于与气质E，它就会更新失败。说明旧的值发生了变化。那我们当然需要返回的是被其它线程改变之后的旧值了，因此放在了do循环体内。


## CAS实现原子操作的三大问题

### ABA问题

所谓ABA问题，就是一个值原来是A，变成了B，又变回了A。这个时候使用CAS是检查不出变化的，但实际上却被更新了两次。

ABA问题的解决思路是在变量前面追加上版本号或者时间戳。从JDK1.5开始，JDK的atomic包里提供了一个类AtomicStampedReference类来解决ABA问题。

这个类的`compareAndSet`方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果二者都相等，才使用CAS设置为新的值和标志。

```java
public boolean compareAndSet(V   expectedReference,
                             V   newReference,
                             int expectedStamp,
                             int newStamp) {
    Pair<V> current = pair;
    return
        expectedReference == current.reference &&
        expectedStamp == current.stamp &&
        ((newReference == current.reference &&
          newStamp == current.stamp) ||
         casPair(current, Pair.of(newReference, newStamp)));
}
```

### 循环时间长开销大

CAS多与自旋结合。如果自旋CAS长时间不成功，会占用大量的CPU资源。

解决思路是让JVM支持处理器提供的pause指令。

pause指令能让自旋失败时cpu睡眠一小段时间再继续自旋，从而使得读操作得频率低很多，为解决内存顺序冲突而导致得CPU流水线重排得代价也会小很多。

### 只能保证一个共享变量得原子操作

这个问题你可能已经知道怎么解决了。有两种解决方案:

1. 使用JDK 1.5开始就提供的AtomicReference类保证对象之间的原子性，把多个变量放到一个对象里面进行CAS操作；
2. 使用锁。锁内的临界区代码可以保证只有当前线程能操作。



# AQS

## AQS简介

AQS是`AbstractQueuedSynchronizer`的简称，即`抽象队列同步器`，从字面意思上理解:

+ 抽象:抽象类，只实现一些主要逻辑，有些方法由子类实现;
+ 队列:使用先进先出(FIFO)队列存储数据
+ 同步:实现了同步功能。

那AQS有什么作用呢?AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广发的同步器，比如我们提到的ReentrantLock,Semaphore,ReentrantReadWriteLock,SynchronousQueue,FutureTask等等皆是基于AQS的。

当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器，只要使用之前实现它的几个`protected`方法就可以了。

## AQS的数据结构

AQS内部使用了一个volatile的变量state来作为资源的标识。同时定义了几个获取和改版state的protected方法，子类可以覆盖这些方法来实现自己的逻辑:

```java
getState()
setState()
compareAndSetState()
```

这三种均是原子操作，其中compareAndSetState()的实现依赖于Unsafe的compareAndSwapInt()方法。

而AQS类本身实现的是一些排队和阻塞的机制，比如具体线程等待队列的维护(如获取资源失败入队/唤醒出队等)。它内部使用了一个先进先出(FIFO)的双端队列，并使用了两个指针head和tail用于标识队列的头部和尾部。其数据结构如图所示:

![img](D:\file\note\study-note\多线程.assets\assets%2F-L_5HvtIhTFW9TQlOF8e%2F-L_5TIKcBFHWPtY3OwUo%2F-L_5TJQjOPACL_iNG1yE%2FAQS数据结构-163903916425311.png)

但它并不是直接存储线程，而是存储拥有线程的Node节点。

## 资源共享模式

资源有两种共享模式，或者说两种同步方式:

+ 独占模式（Exclusive）：资源是独占的，一次只能一个线程获取，如ReentrantLock。
+ 共享模式（Share）：同时可以被多个线程获取，具体的资源个数可以通过参数指定。如Semaphore/CountDownLatch。

一般情况下，子类只需要根据需求实现其中一种模式，当然也有同时实现两种模式的同步类，如`ReadWriteLock`。

AQS中关于这两种资源共享模式的定义源码(均在内部类Node中)。

```java
static final class Node{
    //标记一个节点（对应的线程）在共享模式下等待
    static final Node SHARED = new Node();
    //标记一个节点（对应的线程）在独占模式下等待
    static final Node EXCLUSIVE = null;

    // waitStatus的值，表示该结点（对应的线程）已被取消
    static final int CANCELLED = 1; 
    // waitStatus的值，表示后继结点（对应的线程）需要被唤醒
    static final int SIGNAL = -1;
    // waitStatus的值，表示该结点（对应的线程）在等待某一条件
    static final int CONDITION = -2;
    /*waitStatus的值，表示有资源可用，新head结点需要继续唤醒后继结点（共享模式下，多线程并发释放资源，而head唤醒其后继结点后，需要把多出来的资源留给后面的结点；设置新的head结点时，会继续唤醒其后继结点）*/
    static final int PROPAGATE = -3;

    // 等待状态，取值范围，-3，-2，-1，0，1
    volatile int waitStatus;
    volatile Node prev; // 前驱结点
    volatile Node next; // 后继结点
    volatile Thread thread; // 结点对应的线程
    Node nextWaiter; // 等待队列里下一个等待条件的结点


    // 判断共享模式的方法
    final boolean isShared() {
        return nextWaiter == SHARED;
    }

    Node(Thread thread, Node mode) {     // Used by addWaiter
        this.nextWaiter = mode;
        this.thread = thread;
    }

    // 其它方法忽略，可以参考具体的源码
}

// AQS里面的addWaiter私有方法
private Node addWaiter(Node mode) {
    // 使用了Node的这个构造函数
    Node node = new Node(Thread.currentThread(), mode);
    // 其它代码省略
}
```

> 注意：通过Node我们可以实现两个队列，一是通过prev和next实现CLH队列（线程同步队列，双向队列），二是nextWaiter实现Condition条件上的等待线程队列(单向队列)，这个Condition主要用在ReentrantLock类中。

## AQS的主要方法源码解析

AQS的设计是基于模板方法模式的，它有一些方法必须要子类去实现的，它们主要有:

+ isHeldExclusively():该线程是否正在独占资源。只有用到condition才需要去实现它。
+ tryAcquire(int):独占方式。尝试获取资源，成功则返回true,失败则返回false。
+ tryRelease(int):独占方式。尝试释放资源，成功则返回true,失败则返回false。
+ tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
+ tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。

这些方法虽然都是`protected`方法，但是它们并没有在AQS具体实现，而是直接抛出异常。

```java
protected boolean tryAcquire(int arg) {
    throw new UnsupportedOperationException();
}
```

而AQS实现了一系列主要的逻辑。下面我们从源码来分析一下获取和释放资源的主要逻辑:

### 获取资源

获取资源的入口是acquire(int arg)方法。arg是要获取的资源的个数，在独占模式下始终为1。我们先来看看这个方法的逻辑:

```java
public final void acquire(int arg) {
    if (!tryAcquire(arg) &&
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}
```

首先调用tryAcquire(arg)尝试去获取资源。前面提到了这个方法是在子类具体实现的。

如果获取资源失败，就通过addWaiter(Node.EXCLUSIVE)方法把这个线程插入到等待队列中。其中传入的参数代表要插入的Node是独占式的。这个方法的具体实现：

```java
private Node addWaiter(Node mode) {
    // 生成该线程对应的Node节点
    Node node = new Node(Thread.currentThread(), mode);
    // 将Node插入队列中
    Node pred = tail;
    if (pred != null) {
        node.prev = pred;
        // 使用CAS尝试，如果成功就返回
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    // 如果等待队列为空或者上述CAS失败，再自旋CAS插入
    enq(node);
    return node;
}

// 自旋CAS插入等待队列
private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        if (t == null) { // Must initialize
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}
```

> 上面的两个函数比较好理解，就是在队列的尾部插入新的Node节点，但是需要注意的是由于AQS中会存在多个线程同时争夺资源的情况，因此肯定会出现多个线程同时插入节点的操作，在这里是通过CAS自旋的方式保证了操作的线程安全性。

现在通过addWaiter方法，已经把一个Node放到等待队列尾部了。而处于等待队列的节点是从头节点一个一个去获取资源的。

```java
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        // 自旋
        for (;;) {
            final Node p = node.predecessor();
            // 如果node的前驱结点p是head，表示node是第二个结点，就可以尝试去获取资源了
            if (p == head && tryAcquire(arg)) {
                // 拿到资源后，将head指向该结点。
                // 所以head所指的结点，就是当前获取到资源的那个结点或null。
                setHead(node); 
                p.next = null; // help GC
                failed = false;
                return interrupted;
            }
            // 如果自己可以休息了，就进入waiting状态，直到被unpark()
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
```

> 这里parkAndCheckInterrupt方法内部使用到了LockSupport.park(this)，顺便简单介绍一下park。
> LockSupport类是Java 6 引入的一个类，提供了基本的线程同步原语。LockSupport实际上是调用了Unsafe类里的函数，归结到Unsafe里，只有两个函数：
> + park(boolean isAbsolute, long time)：阻塞当前线程
> + unpark(Thread jthread)：使给定的线程停止阻塞

所以节点进入等待队列后，是调用park使它进入阻塞状态的。只有头节点的线程是处于活跃状态的。

当然，获取资源的方法除了acquire外，还有以下三个:

+ acquireInterruptibly:申请可中断的资源(独占模式)
+ acquireShared:申请共享模式的资源
+ acquireSharedInterruptibly:申请可中断的资源(共享模式)

> 可中断的意思是，在线程中中断时可能会抛出`InterruptedException`

总结起来就是一个流程图:

![img](D:\file\note\study-note\多线程.assets\assets%2F-L_5HvtIhTFW9TQlOF8e%2F-L_5TIKcBFHWPtY3OwUo%2F-L_5TJQpo8U_q8r9AJ5q%2Facquire流程-163904216855113.jpg)

### 释放资源

释放资源相比获取资源来说，会简单许多。在AQS中只有一小段实现。源码:

```java
public final boolean release(int arg) {
    if (tryRelease(arg)) {
        Node h = head;
        if (h != null && h.waitStatus != 0)
            unparkSuccessor(h);
        return true;
    }
    return false;
}

private void unparkSuccessor(Node node) {
    // 如果状态是负数，尝试把它设置为0
    int ws = node.waitStatus;
    if (ws < 0)
        compareAndSetWaitStatus(node, ws, 0);
    // 得到头结点的后继结点head.next
    Node s = node.next;
    // 如果这个后继结点为空或者状态大于0
    // 通过前面的定义我们知道，大于0只有一种可能，就是这个结点已被取消
    if (s == null || s.waitStatus > 0) {
        s = null;
        // 等待队列中所有还有用的结点，都向前移动
        for (Node t = tail; t != null && t != node; t = t.prev)
            if (t.waitStatus <= 0)
                s = t;
    }
    // 如果后继结点不为空，
    if (s != null)
        LockSupport.unpark(s.thread);
}
```

# 线程池原理

## 为什么要使用线程池

使用线程池主要有以下三个原因:

1. 创建/销毁线程需要消耗系统资源，线程池可以复用已经创建的线程。
2. 控制并发的数量。并发数量过多，可能会导致资源消耗过多，从而导致服务器崩溃。（主要原因）
3. 可以对线程做统一管理。

## 线程池原理

Java中的线程池顶层接口是`Executor`接口，`ThreadPoolExecutor`是这个接口的实现类。

我们先看看`ThreadPoolExecutor`类。

### ThreadPoolExecutor提供的构造方法

一共有四个构造方法:

```java
// 五个参数的构造函数
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue)

// 六个参数的构造函数-1
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          ThreadFactory threadFactory)

// 六个参数的构造函数-2
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          RejectedExecutionHandler handler)

// 七个参数的构造函数
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler)
```

涉及5~7个参数

+ int corePoolSize:该线程池中核心线程数最大值
  + 核心线程:线程池中有两类线程，核心线程和非核心线程。核心线程默认情况下会一直存在线程池中，即使这个核心线程什么都不干，而非核心线程如果长时间闲置，就会被销毁。

+ int maximumPoolSize:该线程池中线程总数最大值
  + 该值等于核心线程数量+非核心线程数量

+ long KeepAliveTime:非核心线程闲置超时时长
  + 非核心线程如果闲置状态超过该值，就会被销毁。如果设置allowCoreThreadTimeOut(true),则会也作用于核心线程。

+ TimeUnit unit:KeepAliveTime的单位。

TimeUnit是一个枚举类型，包括以下属性:

> NANOSECONDS ： 1微毫秒 = 1微秒 / 1000 MICROSECONDS ： 1微秒 = 1毫秒 / 1000 MILLISECONDS ： 1毫秒 = 1秒 /1000 SECONDS ： 秒 MINUTES ： 分 HOURS ： 小时 DAYS ： 天

+ BlockingQueue workQueue:阻塞队列，维护者等待执行的Runnable任务对象。
  + 常用的几个阻塞队列
    + LinkedBlockingQueue
      + 链式阻塞队列，底层数据结构是链表，默认大小是Integer.MAX_VALUE,也可以指定大小
    + ArrayBlockingQueue
      + 数组阻塞队列，底层数据结构是数组，需要指定队列的大小。
    + SynchronousQueue
      + 同步队列，内部容量为0，每个put操作必须等待一个take操作，反之亦然。
    + DelayQueue
      + 延迟队列，该队列中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。

+ ThreadFactory threadFactory
  + 创建线程的工厂，用于批量创建线程，统一在创建线程时设置一些参数，如是否守护线程、线程的优先级等。如果不指定，会新建一个默认的线程工厂。
  + ```java
  + static class DefaultThreadFactory implements ThreadFactory {
    // 省略属性
    // 构造函数
    DefaultThreadFactory() {
        SecurityManager s = System.getSecurityManager();
        group = (s != null) ? s.getThreadGroup() :
        Thread.currentThread().getThreadGroup();
        namePrefix = "pool-" +
            poolNumber.getAndIncrement() +
            "-thread-";
    }

    // 省略
    }
  + ```


+ RejectedExecutionHandler handler
  + 拒绝处理策略，线程数量大于最大线程数就会采用拒绝处理策略，四种拒绝处理的策略为；
    + ThreadPoolExecutor.AbortPolicy:默认拒绝处理策略，丢弃任务并抛出RejectedExecutionException异常
    + ThreadPoolExcutor.DiscardPolicy:丢弃新来的任务，但是不抛出异常。
    + ThreadPoolExcutor.DiscardOldestPolicy:丢弃队列头部(最旧的)的任务，然后重新尝试执行程序(如果再次失败，重复此过程)。
    + ThreadPoolExcutor.CallerRunPolicy:由调用线程处理该任务。

### ThreadPoolExecutor的策略

线程池本身有一个调度线程，这个线程就是用于管理布控整个线程池里的各种任务和事务，例如创建线程、销毁线程、任务队列管理、线程队列管理等等。

故线程池也有自己的状态。ThreadPoolExecutor类中定义了一个`volatile int`变量runState来表示线程池的状态，分别为RUNABLE、SHUTDOWN、STOP、TIDYING、TERMINATED

+ 线程池创建后处于RUNNING状态
+ 调用shutdown()方法后处于SHUTDOWN状态，线程池不能接受新的任务，清楚一些空闲worker，会等待阻塞队列的任务完成。
+ 调用shutdownNow()方法后处于STOP状态，线程池不能接受新的任务，中断所有线程，阻塞队列没有被执行的任务全部丢弃。此时,poolSize = 0，阻塞队列的size1也为0。
+ 当所有任务已终止，ctl记录的"任务数量"为0，线程池也会变为TIDYING状态。接着会执行terminated()函数。
  + ThreadPoolExecutor中有一个控制状态的属性叫ctl，它是一个AtomicInteger类型的变量。
+ 线程池处在TIDYING状态时，执行完terminated()方法之后，就会由TIDYING -> TERMINATED,线程池被设置为TERMINATED状态。

### 线程池主要的任务处理流程

处理任务的核心方法是`execute`,我们看看JDK 1.8源码中`ThreadPoolExecutor`是如何处理线程任务的:

```java
public void execute(Runnable command) {
        if (command == null)
            throw new NullPointerException();
        /*
         * Proceed in 3 steps:
         *
         * 1. If fewer than corePoolSize threads are running, try to
         * start a new thread with the given command as its first
         * task.  The call to addWorker atomically checks runState and
         * workerCount, and so prevents false alarms that would add
         * threads when it shouldn't, by returning false.
         *
         * 2. If a task can be successfully queued, then we still need
         * to double-check whether we should have added a thread
         * (because existing ones died since last checking) or that
         * the pool shut down since entry into this method. So we
         * recheck state and if necessary roll back the enqueuing if
         * stopped, or start a new thread if there are none.
         *
         * 3. If we cannot queue task, then we try to add a new
         * thread.  If it fails, we know we are shut down or saturated
         * and so reject the task.
         */
        int c = ctl.get();
        //1.当前线程数小于corePoolSize,则调用addWorker创建核心线程执行任务
        if (workerCountOf(c) < corePoolSize) {
            if (addWorker(command, true))
                return;
            c = ctl.get();
        }
        //2.如果不小于corePoolSize,则将任务添加到workQueue队列
        if (isRunning(c) && workQueue.offer(command)) {
            int recheck = ctl.get();
            //2.1 如果isRunning返回false（状态检查），则remove这个任务，然后执行拒绝策略。
            if (! isRunning(recheck) && remove(command))
                reject(command);
                //2.2 线程池处于Running状态，但是没有线程，则创建线程
            else if (workerCountOf(recheck) == 0)
                addWorker(null, false);
        }
        //3.如果放入workQueue失败，则创建非核心线程执行任务。
        // 如果这时创建非核心线程失败(当前线程总数不小于maximumPoolSize时)，就会执行拒绝策略。
        else if (!addWorker(command, false))
            reject(command);
    }
```

`ctl.get()`是获取线程池状态，用`int`类型表示。第二步中，入队前进行了一次`isRunning`判断，入队之后，又进行了一次`isRunning`判断。入队之后1，又进行了一次`isRunning`判断。

**为什么要二次检查线程池的状态？**

在多线程的环境下，线程池的状态是时刻发生变化的。很有可能刚获取线程池状态后线程池状态就发生改变了。判断是否将`command`加入`workQueue`是线程池之前的状态。倘若没有二次检查，万一线程池处于非RUNNING状态（在多线程环境下很有可能发生），那么`command`永远不会执行。

**总结一下处理流程**

1. 线程总数量 < corePoolSize,无论线程是否空闲，都会新建一个核心线程执行任务（让核心线程数量快速达到corePoolSize,在核心线程数量 < corePoolSize时）。注意，这一步需要获得全局锁。
2. 线程总数量 >= corePoolSize时，新来的线程任务会进入任务队列中等待，然后空闲的1核心线程会依次去缓存队列中取任务来执行(体现了线程复用)。
3. 当缓存队列满了，说明这个时候任务已经多到爆棚，需要一些“临时工”来执行这些任务了。于是会创建非核心线程去执行这个任务。注意，这一步需要获得全局锁。
4. 缓存队列满了，且总线程数达到了maximumPoolSize，则会采用上面提到的拒绝策略进行处理。

整个过程如图所示:

![img](D:\file\note\study-note\多线程.assets\线程池主要的处理流程-16391071038962.png)


### ThreadPoolExecutor如何做到线程复用的？

我们知道，一个线程在创建的时候会指定一个线程任务，当执行完这个线程任务之后，线程自动摧毁。但是线程池却可以复用线程，即一个线程执行完线程任务后不销毁，继续执行另外的线程任务。那么线程池如何做到线程复用的？

原来，ThreadPoolExecutor在创建线程时，会将线程封装成工作线程worker，并放入工作线程组中，然后这个worker反复从阻塞队列中那任务去执行。话不多说，我们继续看看源码。

这里的`addWorker`方法是在上面提到的`execute`方法里面调用的，先看看上半部分:

```java
// ThreadPoolExecutor.addWorker方法源码上半部分
private boolean addWorker(Runnable firstTask, boolean core) {
    retry:
    for (;;) {
        int c = ctl.get();
        int rs = runStateOf(c);

        // Check if queue empty only if necessary.
        if (rs >= SHUTDOWN &&
            ! (rs == SHUTDOWN &&
               firstTask == null &&
               ! workQueue.isEmpty()))
            return false;

        for (;;) {
            int wc = workerCountOf(c);
            if (wc >= CAPACITY ||
                // 1.如果core是ture,证明需要创建的线程为核心线程，则先判断当前线程是否大于核心线程
                // 如果core是false,证明需要创建的是非核心线程，则先判断当前线程数是否大于总线程数
                // 如果不小于，则返回false
                wc >= (core ? corePoolSize : maximumPoolSize))
                return false;
            if (compareAndIncrementWorkerCount(c))
                break retry;
            c = ctl.get();  // Re-read ctl
            if (runStateOf(c) != rs)
                continue retry;
            // else CAS failed due to workerCount change; retry inner loop
        }
    }
```

上半部分主要是判断线程数量是否超出阈值，超过了就返回false。我们继续看下半部分:

```java
    // ThreadPoolExecutor.addWorker方法源码下半部分
    boolean workerStarted = false;
    boolean workerAdded = false;
    Worker w = null;
    try {
        // 1.创建一个worker对象
        w = new Worker(firstTask);
        // 2.实例化一个Thread对象
        final Thread t = w.thread;
        if (t != null) {
            // 3.线程池全局锁
            final ReentrantLock mainLock = this.mainLock;
            mainLock.lock();
            try {
                // Recheck while holding lock.
                // Back out on ThreadFactory failure or if
                // shut down before lock acquired.
                int rs = runStateOf(ctl.get());

                if (rs < SHUTDOWN ||
                    (rs == SHUTDOWN && firstTask == null)) {
                    if (t.isAlive()) // precheck that t is startable
                        throw new IllegalThreadStateException();
                    workers.add(w);
                    int s = workers.size();
                    if (s > largestPoolSize)
                        largestPoolSize = s;
                    workerAdded = true;
                }
            } finally {
                mainLock.unlock();
            }
            if (workerAdded) {
                // 4.启动这个线程
                t.start();
                workerStarted = true;
            }
        }
    } finally {
        if (! workerStarted)
            addWorkerFailed(w);
    }
    return workerStarted;
}
```

创建worker对象，并初始化一个`Thread`对象，然后启动这个线程对象。

我们接着看看`worker`类，进展示部分源码:

```java
// Worker类部分源码
private final class Worker extends AbstractQueuedSynchronizer implements Runnable{
    final Thread thread;
    Runnable firstTask;

    Worker(Runnable firstTask) {
        setState(-1); // inhibit interrupts until runWorker
        this.firstTask = firstTask;
        this.thread = getThreadFactory().newThread(this);
    }

    public void run() {
            runWorker(this);
    }
    //其余代码略...
}
```

`Worker`类实现了`Runnable`接口，所以`Worker`也是一个线程任务。在构造方法中，创建了一个线程，线程的任务就是自己。故`addWorker`方法源码下半部分中的第4步`t.start`,会触发`Worker`类的run方法被JVM调用。

我们再看看`runWorker`的逻辑:

```java
/**
     * Main worker run loop.  Repeatedly gets tasks from queue and
     * executes them, while coping with a number of issues:
     *
     * 1. We may start out with an initial task, in which case we
     * don't need to get the first one. Otherwise, as long as pool is
     * running, we get tasks from getTask. If it returns null then the
     * worker exits due to changed pool state or configuration
     * parameters.  Other exits result from exception throws in
     * external code, in which case completedAbruptly holds, which
     * usually leads processWorkerExit to replace this thread.
     *
     * 2. Before running any task, the lock is acquired to prevent
     * other pool interrupts while the task is executing, and then we
     * ensure that unless pool is stopping, this thread does not have
     * its interrupt set.
     *
     * 3. Each task run is preceded by a call to beforeExecute, which
     * might throw an exception, in which case we cause thread to die
     * (breaking loop with completedAbruptly true) without processing
     * the task.
     *
     * 4. Assuming beforeExecute completes normally, we run the task,
     * gathering any of its thrown exceptions to send to afterExecute.
     * We separately handle RuntimeException, Error (both of which the
     * specs guarantee that we trap) and arbitrary Throwables.
     * Because we cannot rethrow Throwables within Runnable.run, we
     * wrap them within Errors on the way out (to the thread's
     * UncaughtExceptionHandler).  Any thrown exception also
     * conservatively causes thread to die.
     *
     * 5. After task.run completes, we call afterExecute, which may
     * also throw an exception, which will also cause thread to
     * die. According to JLS Sec 14.20, this exception is the one that
     * will be in effect even if task.run throws.
     *
     * The net effect of the exception mechanics is that afterExecute
     * and the thread's UncaughtExceptionHandler have as accurate
     * information as we can provide about any problems encountered by
     * user code.
     *
     * @param w the worker
     */
    final void runWorker(Worker w) {
        Thread wt = Thread.currentThread();
        Runnable task = w.firstTask;
        w.firstTask = null;
        //1. 线程启动之后，通过unlock方法释放锁
        w.unlock(); // allow interrupts
        boolean completedAbruptly = true;
        try {
            //2.Worker执行firstTask或从workQueue中获取任务，如果getTask方法不返回null,循环不退出
            while (task != null || (task = getTask()) != null) {
                //2.1 进行加锁操作，保证thread不被其他线程中断（除非线程池被中断）
                w.lock();
                // If pool is stopping, ensure thread is interrupted;
                // if not, ensure thread is not interrupted.  This
                // requires a recheck in second case to deal with
                // shutdownNow race while clearing interrupt
                //2.2检查线程池状态，倘若线程池处于中断状态，当前线程被中断。
                if ((runStateAtLeast(ctl.get(), STOP) ||
                     (Thread.interrupted() &&
                      runStateAtLeast(ctl.get(), STOP))) &&
                    !wt.isInterrupted())
                    wt.interrupt();
                try {
                    //2.3执行beforeExecute
                    beforeExecute(wt, task);
                    Throwable thrown = null;
                    try {
                        //2.4执行任务
                        task.run();
                    } catch (RuntimeException x) {
                        thrown = x; throw x;
                    } catch (Error x) {
                        thrown = x; throw x;
                    } catch (Throwable x) {
                        thrown = x; throw new Error(x);
                    } finally {
                        //2.5执行afterExecute方法
                        afterExecute(task, thrown);
                    }
                } finally {
                    task = null;
                    w.completedTasks++;
                    //2.6解锁操作
                    w.unlock();
                }
            }
            completedAbruptly = false;
        } finally {
            processWorkerExit(w, completedAbruptly);
        }
    }
```

首先去执行创建这个worker时就有的任务，当执行完这个任务后，worker的生命周期并没有结束，在while循环中，worker会不断地调用getTask方法从阻塞队列中获取任务然后调用`task.run()`执行任务，从而达到复用线程的目的。只要getTask方法不返回bull，此线程就不会退出。

当然，核心线程池中创建的线程想要拿到阻塞队列中的任务，先要判断线程池的状态，如果STOP或者TERMINATED,返回null.

最后看看`getTask`方法的实现:

```java
private Runnable getTask() {
        boolean timedOut = false; // Did the last poll() time out?

        for (;;) {
            int c = ctl.get();
            int rs = runStateOf(c);

            // Check if queue empty only if necessary.
            if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) {
                decrementWorkerCount();
                return null;
            }

            int wc = workerCountOf(c);

            // Are workers subject to culling?
            //1.allowCoreThreadTimeOut变量默认是false,核心线程即使空闲也不会被销毁
            //如果为true,核心线程在KeepAliveTime内仍空闲则会被销毁
            boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;

            //2.如果运行线程数超过了最大线程数，但是缓存队列已经空了，这时递减worker数量
            //如果有设置允许线程超时或者线程数量超过了核心线程数量
            //并且线程在规定时间内均未poll到任务且队列为空则递减worker数量
            if ((wc > maximumPoolSize || (timed && timedOut))
                && (wc > 1 || workQueue.isEmpty())) {
                if (compareAndDecrementWorkerCount(c))
                    return null;
                continue;
            }

            try {
                // 3.如果timed为true(想想哪些情况下timed为true),则会调用workQueue的poll方法获取任务.
                // 超时时间是keepAliveTime。如果超过keepAliveTime时长，
                // poll返回了null，上边提到的while循序就会退出，线程也就执行完了。
                // 如果timed为false（allowCoreThreadTimeOut为falsefalse
                // 且wc > corePoolSize为false），则会调用workQueue的take方法阻塞在当前。
                // 队列中有任务加入时，线程被唤醒，take方法返回任务，并执行。
                Runnable r = timed ?
                    workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
                    workQueue.take();
                if (r != null)
                    return r;
                timedOut = true;
            } catch (InterruptedException retry) {
                timedOut = false;
            }
        }
    }
```

核心的线程会一直卡在`workQueue.take`方法，被阻塞并挂起，不会占用CPU资源，直到拿到Runnable然后返回(当然如果allowCoreThreadTimeOut设置为true，那么核心线程就回去调用poll方法，因为poll可能会返回null，所以这时候核心线程满足超时任务也会被销毁)。

非核心线程会workQueue.poll(keepAliveTime,TimeUnit.NANOSECONDS),如果超时还没有拿到，下一次循环判断compareAndDecrementWorkerCount就会返回null，Worker对象的run()方法循环体的判断为null，任务结束，然后线程被系统回收。

## 四种常见的线程池

Executors类中提供的几个静态方法来创建线程池。

### newCachedThreadPool

```java
public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue<Runnable>());
}
```

CacheThreadPool的运行流程如下:

1. 提交任务进线程池
2. 因为corePoolSize为0的关系，不创建核心线程，线程池最大为Integer.MAX_VALUE.
3. 尝试将任务添加到SynchronousQueue队列。
4. 如果SynchronousQueue入列成功，等待被当前运行的线程空闲后拉取执行。如果当前没有空闲线程，那么就创建一个非核心线程，然后从SynchronousQueue拉取任务并在当前线程执行。
5. 如果SynchronousQueue已有任务在等待，入列操作将会阻塞。

当需要执行很多短时间的任务时，CachedThreadPool的线程复用率比较高，会显著提高性能，而且线程60s后会回收，意味着即使没有任务进来，CacheThreadPool并不会占用很多资源。

### newFixedThreadPool

```java
public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>());
}
```

核心线程数量和总线程数量相等，都是传入的参数nThreads,所以只能创建核心线程，不能创建非核心线程。因为LinkedBlockingQueue的默认大小是Integer.MAX_VALUE,故如果核心线程空闲，则交给核心线程处理；如果核心新城不空闲，则入列等待，知道核心线程空闲。

与CachedThreadPool的区别:

+ 因为corePoolSize == maximumPoolSize,所以FixedThreadPool只会创建核心线程。而CachedThreadPool因为corePoolSize = 0,所以只会创建非核心线程。
+ 在getTask()方法，如果队列里没有任务可取，线程会一直阻塞在LinkedBlockingQueue.take(),线程不会被回收。CachedThreadPool会在60s后收回。
+ 由于线程不会被回收，会一直卡在阻塞，所以没有任务的情况下，FixedThreadPool占用资源更多。
+ 都几乎不会触发拒绝策略，但是原理不同。FixedThreadPool是因为阻塞队列可以很大(最大为Integer最大值)，故几乎不会触发拒绝策略;CachedThreadPool是因为线程池很大(最大为Integer最大值)，几乎不会导致线程数量大于最大线程数，故几乎不会触发拒绝策略。

### newScheduledThreadPool

创建一个定长线程池，支持定时及周期性任务执行。

```java
public static ExecutorService newSingleThreadExecutor() {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExecutor(1, 1,
                                0L, TimeUnit.MILLISECONDS,
                                new LinkedBlockingQueue<Runnable>()));
}
```

有且仅有一个核心线程(corePoolSize == maximumPoolSize = 1),使用了LinkedBlockingQueue(容量很大)，所以，不会创建非核心线程。所有任务按照先来先执行的顺序执行。如果这个唯一的线程不空闲，那么新来的任务会存储在任务队列里等待执行。

### newScheduledThreadPool

创建一个定长线程池，支持定时及周期性任务执行

```java
public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
    return new ScheduledThreadPoolExecutor(corePoolSize);
}

//ScheduledThreadPoolExecutor():
public ScheduledThreadPoolExecutor(int corePoolSize) {
    super(corePoolSize, Integer.MAX_VALUE,
          DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS,
          new DelayedWorkQueue());
}
```

四种常见的线程池基本够我们使用了，但是《阿里把把开发手册》不建议我们直接使用Executors类中的线程池，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学需要更加明确线程池的运行规则，规避资源耗尽的风险。
但如果你及团队本身对线程池非常熟悉，又确定业务规模不会大到资源耗尽的程度（比如线程数量或任务队列长度可能达到Integer.MAX_VALUE）时，其实是可以使用JDK提供的这几个接口的，它能让我们的代码具有更强的可读性。


# 阻塞队列

## 阻塞队列的由来

我们假设一种场景，生产者一直生产资源，消费者一直消费资源，资源存储在一个缓冲池中，生产者将生产的资源存进缓冲池中，消费者从缓冲池中，消费者从缓冲池中拿到资源进行消费，这就是大名鼎鼎的生产者-消费者模式。

该模式能够简化开发过程，一方面消除了生产者类与消费者类之间的代码依赖性，另一方面将生产数据的过程与使用数据的过程解耦简化负载。

我们自己coding实现这个模式的时候，因为需要让多个线程操作共享变量(即资源)，所以很容易引发线程安全问题，造成重复消费和死锁,尤其是生产者和消费者存在多个的情况。另外，当缓冲池空了，我们需要阻塞消费者，唤醒生产者；当缓冲池满了，我们需要阻塞生产者，唤醒消费者，这些等待-唤醒逻辑都需要自己实现。

这么容易出错的事情，JDK当然帮我们做啦，这就是阻塞队列(BlockingQueue),你只管往里面存，取就行，而不用担心多线程环境下存、取共享变量的线程安全问题。

> BlockingQueue是Java.util.concurrent包下重要的数据结构，区别于普通的队列，BlockingQueue提供了线程安全的队列访问方式，并发包下很多高级同步类的实现都是基于BlockingQueue实现的。

BlockingQueue一般用于生产者-消费者模式，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。BlockingQueue就是存放元素的容器。

## BlockingQueue的操作方法

阻塞队列提供了四组不同的方法用于插入、移除、检查元素:

| 方法\处理方式 | 抛出异常  | 返回特殊值 | 一直阻塞 | 超时退出           |
| ------------- | --------- | ---------- | -------- | ------------------ |
| 插入方法      | add(e)    | offer(e)   | put(e)   | offer(e,time,unit) |
| 移除方法      | remove()  | poll()     | take()   | poll(time,unit)    |
| 检查方法      | element() | peek()     |          |                    |


+ 抛出异常:如果试图的操作无法立即执行，抛异常。当阻塞队列满时，再往队列里插入元素，会抛出IllegalStateException("Queue full")异常。当队列为空时，从队列里获取元素时会抛出NoSuchElementException异常。
+ 返回特殊值:如果试图的操作无法立即执行，返回一个特殊值，通常是true/false。
+ 一直阻塞:如果试图的操作无法立即执行,则一直阻塞或者响应中断。
+ 超时退出:如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行，但等待时间不会超过给定值。返回一个特定值以告知该操作是否成功，通常是true/false。

**注意之处**
+ 不能往阻塞队列中插入null，会抛出空指针异常
+ 可以访问阻塞队列中的任意元素，调用remove(o)可以将队列之中的特定对象移除，但并不高效，尽量避免使用。


## BlockingQueue的实现类

### ArrayBlockingQueue

由数组结构组成的有界阻塞队列。内部结构是数组，故具有数组的特性。

```java
public ArrayBlockingQueue(int capacity, boolean fair){
    //..省略代码
}
```

可以初始化队列大小，且一旦初始化不能改变。构造方法中的fair表示控制对象的内部锁是否采用公平锁，默认是非公平锁。

### LinkedBlockingQueue

由链表结构组成的有界阻塞队列。内部结构是链表，具有链表的特性。默认队列的大小是`Integer.MAX_VALUE`,也可以指定大小。此队列按照先进先出的原则对元素进行排序。

### DelayQueue

```java
该队列中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素 。注入其中的元素必须实现 java.util.concurrent.Delayed 接口。 

DelayQueue是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。 
```


### PriorityBlockingQueue

```java
基于优先级的无界阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定），内部控制线程同步的锁采用的是公平锁。
```


### SynchronousQueue

这个队列比较特殊，没有任何容量，甚至连一个队列的容量都没有。并且每个put必须等待一个take,反之亦然。

需要区别容量为1的ArrayBlockingQueue、LinkedBlockingQueue。

以下方法的返回值，可以帮助理解这个队列:

+ iterator()永远返回空，因为里面没有东西
+ peek()永远返回null
+ put()往queue放进去一个element以后就一直wait直到有其它thread进来把这个element取走。
+ offer()往queue里放一个element后立即返回，如果碰巧这个element被另一个thread取走了，offer方法返回true，认为offer成功；否则返回false。
+ take()取出并且remove掉queue里的element，取不到东西他会一直等。
+ poll()取出并且remove掉queue里的element，只有到碰巧另外一个线程正在往queue里offer数据或者pull数据的时候，该方法才会取到东西。否则立即返回null。
+ isEmpty()永远返回true
+ remove()&removeAll()永远返回false

**注意**

PriorityBlockingQueue不会阻塞数据生产者(因为队列是无界的)，而只会在没有可消费的数据时，阻塞数据的消费者。因此使用的时候要特别注意，生产者生产数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。对于使用默认大小的LinkedBlockingQueue也是一样的。

## 阻塞队列的原理

阻塞队列的原理很简单，利用Lock锁的多条件(Condition)阻塞。接下来我们分析ArrayBlockingQueue JDK 1.8的源码。

首先是构造器，除了初始化队列的大小和是否是公平锁之外，还对同一个锁(lock)初始化了两个监视器，分别是notEmpty和notFull。这两个监视器的作用目前可以简单理解为标记分组，当该线程是put操作时，给他加上监视器notFull,标记这个线程是消费者。

```java
//数据元素数组
final Object[] items;
//下一个待取出元素索引
int takeIndex;
//下一个待添加元素索引
int putIndex;
//元素个数
int count;
//内部锁
final ReentrantLock lock;
//消费者监视器
private final Condition notEmpty;
//生产者监视器
private final Condition notFull;  

public ArrayBlockingQueue(int capacity, boolean fair) {
    //..省略其他代码
    lock = new ReentrantLock(fair);
    notEmpty = lock.newCondition();
    notFull =  lock.newCondition();
}
```

put操作的源码

```java
public void put(E e) throws InterruptedException {
        checkNotNull(e);
        final ReentrantLock lock = this.lock;
        //1.自旋拿锁
        lock.lockInterruptibly();
        try {
            //2.判断对列是否满了
            while (count == items.length)
                //2.1如果满了，阻塞该线程，并标记为notFull线程，
                //等待notFull的唤醒，唤醒之后继续执行while循环。
                notFull.await();
            //3.如果没有满，则进入队列
            enqueue(e);
        } finally {
            lock.unlock();
        }
    }


private void enqueue(E x) {
        // assert lock.getHoldCount() == 1;
        // assert items[putIndex] == null;
        final Object[] items = this.items;
        items[putIndex] = x;
        if (++putIndex == items.length)
            putIndex = 0;
        count++;
        //4.唤醒一个等待的线程
        notEmpty.signal();
    }
```

总结put的流程:

1. 所有执行put操作的线程竞争lock锁，拿到了lock锁的线程进入下一步，没有拿到lock锁的线程自旋竞争锁。
2. 判断阻塞队列是否满了，如果满了，则调用await方法阻塞这个线程，并标记为notFull(生产者)线程，同时释放lock锁，等待被消费者线程唤醒。
3. 如果没有满，则调用enqueue方法将元素put进阻塞队。注意这一步的线程还有一种情况是第二步中阻塞的线程被唤醒且又拿到了lock锁的线程。
4. 唤醒一个标记为notEmpty（消费者）的线程。


**take操作的源码**

```java
public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        while (count == 0)
            notEmpty.await();
        return dequeue();
    } finally {
        lock.unlock();
    }
}
private E dequeue() {
    // assert lock.getHoldCount() == 1;
    // assert items[takeIndex] != null;
    final Object[] items = this.items;
    @SuppressWarnings("unchecked")
    E x = (E) items[takeIndex];
    items[takeIndex] = null;
    if (++takeIndex == items.length)
        takeIndex = 0;
    count--;
    if (itrs != null)
        itrs.elementDequeued();
    notFull.signal();
    return x;
}
```

take操作和put操作的流程是类似的，总结一下take操作的流程:

1. 所有执行take操作的线程竞争lock锁，拿到了lock锁的线程进入下一步，没有拿到lock锁的线程自旋竞争锁。
2. 判断阻塞对列是否为空，如果是空，则调用await方法阻塞这个线程，并标记为notEmpty(消费者)线程，同时释放lock锁，等待被生产者线程唤醒。
3. 如果没有空，则调用dequeue方法。注意这一步的线程还有一种情况是第二步中的线程被唤醒且又拿到了lock锁的线程。
4. 唤醒一个标记为notFull（生产者）的线程。

**注意**

1. put和take操作都需要先获取锁，没有获取到锁的线程会被挡在第一道大门之外自旋拿锁，知道获取到锁。
2. 就算拿到锁了之后，也不一定会顺利进行put/take操作，需要判断队列是否可用(是否满/空)，如果不可用，则会被阻塞，并释放锁。
3. 在第2点被阻塞的线程会被唤醒，但是在唤醒之后，依然需要拿到锁才能继续往下执行，否则，自旋拿锁，拿到锁了再while判断队列是否可用(这也是为甚么不用if判断，而使用while判断的原因)。

## 示例和使用场景

### 生产者-消费者模型

```java
public class Test {
    private int queueSize = 10;
    private ArrayBlockingQueue<Integer> queue = new ArrayBlockingQueue<Integer>(queueSize);

    public static void main(String[] args)  {
        Test test = new Test();
        Producer producer = test.new Producer();
        Consumer consumer = test.new Consumer();

        producer.start();
        consumer.start();
    }

    class Consumer extends Thread{

        @Override
        public void run() {
            consume();
        }

        private void consume() {
            while(true){
                try {
                    queue.take();
                    System.out.println("从队列取走一个元素，队列剩余"+queue.size()+"个元素");
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }
    }

    class Producer extends Thread{

        @Override
        public void run() {
            produce();
        }

        private void produce() {
            while(true){
                try {
                    queue.put(1);
                    System.out.println("向队列取中插入一个元素，队列剩余空间："+(queueSize-queue.size()));
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }
    }
}
```

下面是这个例子的输出片段

```
从队列取走一个元素，队列剩余0个元素
从队列取走一个元素，队列剩余0个元素
向队列取中插入一个元素，队列剩余空间：9
向队列取中插入一个元素，队列剩余空间：9
向队列取中插入一个元素，队列剩余空间：9
向队列取中插入一个元素，队列剩余空间：8
向队列取中插入一个元素，队列剩余空间：7
向队列取中插入一个元素，队列剩余空间：6
向队列取中插入一个元素，队列剩余空间：5
向队列取中插入一个元素，队列剩余空间：4
向队列取中插入一个元素，队列剩余空间：3
向队列取中插入一个元素，队列剩余空间：2
向队列取中插入一个元素，队列剩余空间：1
向队列取中插入一个元素，队列剩余空间：0
从队列取走一个元素，队列剩余1个元素
从队列取走一个元素，队列剩余9个元素
```

注意，这个例子中的输出结果看起来可能有问题，比如有几行在插入一个元素之后，队列的剩余空间不变。这是由于System.out.println语句没有锁。考虑到这样的情况：线程1在执行完put/take操作后立即失去CPU时间片，然后切换到线程2执行put/take操作，执行完毕后回到线程1的System.out.println语句并输出，发现这个时候阻塞队列的size已经被线程2改变了，所以这个时候输出的size并不是当时线程1执行完put/take操作之后阻塞队列的size，但可以确保的是size不会超过10个。实际上使用阻塞队列是没有问题的。

# 锁接口和类

前面我们介绍了Java原生的锁-基于对象的锁，它一般是配合synchronized关键字来使用的。实际上，Java在`Java.util.concurrent.locks`包下，还为我们提供了几个关于锁的类和接口。它们有更强大的功能或性能。

## synchronized的不足之处

我们先来看看`synchronized`有什么不足之处。

+ 如果临界区是只读操作，其实可以多线程一起执行，但使用synchronized的话，同一时间只能有一个线程执行。
+ synchronized无法知道线程有没有成功获取到锁
+ 使用synchronized，如果临界区因为IO或者sleep方法等原因阻塞了，而当前线程又没有释放锁，就会导致所有线程等待。

而这些都是locks包下的锁可以解决的。

## 锁的几种分类

锁可以根据以下几种反射光hi来进行分类，下面我们将逐一介绍。

### 可重入锁和非可重入锁

所谓重入锁，顾名思义。就是支持重新进入的锁，也就是说这个锁支持一个线程对资源重复加锁。

synchronized关键字就是使用的重入锁。比如说，你在一个synchronized实例方法里面调用另一个本实例的synchronized实例方法，它可以重新进入这个锁，不会出现任何异常。

如果我们自己在继承AQS实现同步器的时候，没有考虑到占有锁的线程再次获取锁的场景，可能就会导致线程阻塞，那这个就是一个"非可重入锁"。

`ReentrantLock`的中文意思就是可重入锁。

### 公平锁与非公平锁

这里的"公平"，其实通俗意义来说就是"先来后到"，也就是FIFO。如果对一个锁来说，先对锁获取请求的线程一定会先被满足，后对锁获取请求的线程后被满足，那这个锁就是公平的。反之，那就是不公平的。

一般情况下，非公平锁能提升一定的效率。但是非公平锁可能会发生线程饥饿(有一些线程长时间得不到锁)的情况。所以要根据实际的需求来选择非公平锁和公平锁。

ReentrantLock支持非公平锁和公平锁两种。

### 读写锁和排它锁

我们前面讲到的synchronized用的锁和ReemtrantLock，其实都是"排它锁"。也就是说，这些锁在同一时刻只允许一个线程进行访问。

而读写锁可以在同一时刻允许多个读线程访问。Java提供了ReentrantReadWriteLock类作为读写锁的默认实现，内部维护了两个锁:一个读锁，一个写锁。通过分离读锁和写锁，使得在"读多写少"的环境下，大大地提高了性能。

> 注意，即使用读写锁，在写线程访问时，所有的读线程和其它写线程均被阻塞。

可见，只是synchronized是远远不能满足多样化的业务对锁的要求的。

## JDK中有关锁的一些接口和类

众所周知，JDK中关于并发的类大多都在`Java.util.concurrent`以下简称juc包下。而juc.locks包看名字就知道，是提供了一些并发锁的工具类

### 抽象类AQS/AQLS/AOS

这三个抽象类有一定的关系，所以这里放到一起讲。

首先我们看AQS(AbstractQueueSynchronizer)，之前专门有章节介绍这个类，它是在JDK 1.5发布的，提供了一个"队列同步器"的基本功能实现。而AQS里面的"资源"是用一个int类型的数据来表示的，有时候我们的业务需求资源的数量超出了int的范围，所以在JDK 1.6中，多了一个AQLS（AbstractQueueLongSynchronizer）。它的代码跟AQS几乎一样，只是把资源的类型变成了long类型。

AQS和AQLS都继承了一个类叫AOS（AbstractOwnableSynchronizer）。这个类也是在JDK 1.6中出现的。这个类只有几行简单的代码。从源码类上的注释可以知道，它是用于表示锁和持有者之间的关系(独占模式)。可以看一下它的主要方法:

```java
// 独占模式，锁的持有者  
private transient Thread exclusiveOwnerThread;  

// 设置锁持有者  
protected final void setExclusiveOwnerThread(Thread t) {  
    exclusiveOwnerThread = t;  
}  

// 获取锁的持有线程  
protected final Thread getExclusiveOwnerThread() {  
    return exclusiveOwnerThread;  
}
```

### 接口Condition/Lock/ReadWriteLock

juc.locks包下共有三个接口:`Condition`、`Lock`、`ReadWriteLock`。其中，Lock和ReadWriteLock从名字就可以看得出来，分别是锁和读写锁的意思。Lock接口里面有一些获取缩合释放锁的声明，而ReadWriteLock里面只有连哥哥方法，分别返回"读锁"和"写锁":

```java
public interface ReadWriteLock {
    Lock readLock();
    Lock writeLock();
}
```

Lock接口中有一个方法是可以获得一个`Condition`:

```java
Condition newCondition();
```

之前我们提到了每个对象都可以用继承自`Object`的wait/notify方法来实现等待/通知机制。而Condition接口来提供了类似Object监视器的方法，通过与Lock配合来实现等待/通知机制。

那为什么既然有Object的监视器方法了，还要用Condition呢?这里有一个二者简单的对比

| 对比项                                         | Object监视器                  | Condition                                                   |
| ---------------------------------------------- | ----------------------------- | ----------------------------------------------------------- |
| 前置条件                                       | 获取对象的锁                  | 调用Lock.lock获取锁，调用Lock.newCondition获取Condition对象 |
| 调用方式                                       | 直接调用，比如object.notify() | 直接调用，比如condition.await()                             |
| 等待队列的个数                                 | 一个                          | 多个                                                        |
| 当前线程释放锁进入等待状态                     | 支持                          | 支持                                                        |
| 当前线程释放锁进入等待状态，在等待状态中不中断 | 不支持                        | 支持                                                        |
| 当前线程释放锁并进入超时等待状态               | 支持                          | 支持                                                        |
| 当前线程释放锁并进入等待状态直到将来的某个时间 | 不支持                        | 支持                                                        |
| 唤醒等待队列中的一个线程                       | 支持                          | 支持                                                        |
| 唤醒等待队列中的全部线程                       | 支持                          | 支持                                                        |



Condition和Object的wait/notify基本相似。其中，Condition的await方法对应的是Object的wait方法，而Condition的signal/signalAll方法则对应Object的notify/notifyAll()。但Condition类似于Object的等待/通知机制的加强版。我们来看看主要的方法:

| 方法名称               | 描述                                                         |
| ---------------------- | ------------------------------------------------------------ |
| await()                | 当前线程进入等待状态知道被通知(signal)或者中断;当前线程进入运行状态并从await()方法返回的场景包括:(1)其它线程调用相同Condition对象的signal/signalAll方法，摈弃给当前线程被唤醒;(2)其它线程调用interrupt方法中断当前线程； |
| awaitUninterruptibly() | 当前线程进入等待状态直到被通知，在此过程中对中断信号不敏感，不支持中断当前线程。 |
| awaitNanos(long)       | 当前线程进入等待状态，直到被通知、中断或者超时。如果返回值小于1等于0,可以认定就是超时了 |
| awaitUntil(Date)       | 当前线程进入等待状态直到被通知、中断或者超时。如果没到指定时间被通知，则返回true，否则返回false |
| signal()               | 唤醒一个等待在Condition上的线程，被唤醒的线程在方法返回前必须获得与Condition对象关联的锁 |
| signalAll()            | 唤醒所有等待在Condition上的线程，能够从await()等方法返回的线程必须先获得与Condition对象关联的锁 |


### ReentrantLock

ReentrantLock是一个非抽象类，它是Lock接口的JDK默认实现，实现了锁的基本功能。从名字上看，它是一个"可重入"锁，从源码上看，它内部有一个抽象类Sync,是继承了AQS，自己实现的一个同步器。同时，ReentrantLock内部有两个非抽象类NonfairSync和FairSync,它们都继承了Sync。从名字上看得出，分别是"非公平同步器"和"公平同步器"的意思。这意味着ReentrantLock可以支持"公平锁"和"非公平锁"。

通过看着两个同步器的源码可以发现，它们的实现都是"独占的"。都调用了AQS的`setExclusiveOwnerThread`方法，所以`ReentrantLock`的锁的"独占"的，也就是说，它的锁都是"排它锁"，不能共享。

在ReentrantLock的构造方法里，可以传入一个boolean类型的参数，来指定它是否是一个公平锁，默认情况下是非公平的。这个参数一旦实例化就不能修改，只能通过isFair()方法来查看。

### ReentrantReadWriteLock

这个类也是一个非抽象类，它是ReadWriteLock接口的JDK默认实现。它与Reentrantlock的功能类似，同样是可重入的，支持非公平锁和公平锁。不同的是，它还支持"读写锁"。

ReentrantReadWriteLock内部的结构大概是这样:

```java
// 内部结构
private final ReentrantReadWriteLock.ReadLock readerLock;
private final ReentrantReadWriteLock.WriteLock writerLock;
final Sync sync;
abstract static class Sync extends AbstractQueuedSynchronizer {
    // 具体实现
}
static final class NonfairSync extends Sync {
    // 具体实现
}
static final class FairSync extends Sync {
    // 具体实现
}
public static class ReadLock implements Lock, java.io.Serializable {
    private final Sync sync;
    protected ReadLock(ReentrantReadWriteLock lock) {
            sync = lock.sync;
    }
    // 具体实现
}
public static class WriteLock implements Lock, java.io.Serializable {
    private final Sync sync;
    protected WriteLock(ReentrantReadWriteLock lock) {
            sync = lock.sync;
    }
    // 具体实现
}

// 构造方法，初始化两个锁
public ReentrantReadWriteLock(boolean fair) {
    sync = fair ? new FairSync() : new NonfairSync();
    readerLock = new ReadLock(this);
    writerLock = new WriteLock(this);
}

// 获取读锁和写锁的方法
public ReentrantReadWriteLock.WriteLock writeLock() { return writerLock; }
public ReentrantReadWriteLock.ReadLock  readLock()  { return readerLock; }
```

可以看到，它同样是内部维护了两个同步器。且维护了两个Lock的实现类ReadLock和writeLock。从源码可以发现，这两个内部类用的是外部类的同步器。

ReentrantReadWriteLock实现了读写锁，但它有一个小弊端，就是在"写"操作的时候，其它线程不能写也不能读。我们称这种现象为"写饥饿"，将在后文的StampedLock类继续讨论这个问题。

### StampedLock

`StampedLock`类是在Java 8才发布的，也是Doug Lea大神所写，有人号称它为锁的性能之王。它没有实现Lock接口和ReadWriteLock接口，但它其实是实现了"读写锁"的功能，并且性能比ReentrantReadWriteLock更高。StampedLock还把读锁分为了"乐观读锁"和"悲观读锁"两种。

前面提到了ReentrantReadWriteLock会发生"写饥饿"的现象，但StampedLock不会。它是怎么做到的呢?它的核心思想在于，在读的时候如果发生了写，应该通过重试的方式来获取新的值，而不应该阻塞写操作。这种模式也就是典型的无锁编程思想，和CAS自旋的思想是一样的。这种操作方式决定了StampedLock在读线程非常多而写线程非常少的场景下非常适用，同时还避免了写饥饿情况的发生。

```java
class Point {
   private double x, y;
   private final StampedLock sl = new StampedLock();

   // 写锁的使用
   void move(double deltaX, double deltaY) {
     long stamp = sl.writeLock(); // 获取写锁
     try {
       x += deltaX;
       y += deltaY;
     } finally {
       sl.unlockWrite(stamp); // 释放写锁
     }
   }

   // 乐观读锁的使用
   double distanceFromOrigin() {
     long stamp = sl.tryOptimisticRead(); // 获取乐观读锁
     double currentX = x, currentY = y;
     if (!sl.validate(stamp)) { // //检查乐观读锁后是否有其他写锁发生，有则返回false
        stamp = sl.readLock(); // 获取一个悲观读锁
        try {
          currentX = x;
          currentY = y;
        } finally {
           sl.unlockRead(stamp); // 释放悲观读锁
        }
     }
     return Math.sqrt(currentX * currentX + currentY * currentY);
   }

   // 悲观读锁以及读锁升级写锁的使用
   void moveIfAtOrigin(double newX, double newY) {
     long stamp = sl.readLock(); // 悲观读锁
     try {
       while (x == 0.0 && y == 0.0) {
         // 读锁尝试转换为写锁：转换成功后相当于获取了写锁，转换失败相当于有写锁被占用
         long ws = sl.tryConvertToWriteLock(stamp); 

         if (ws != 0L) { // 如果转换成功
           stamp = ws; // 读锁的票据更新为写锁的
           x = newX;
           y = newY;
           break;
         }
         else { // 如果转换失败
           sl.unlockRead(stamp); // 释放读锁
           stamp = sl.writeLock(); // 强制获取写锁
         }
       }
     } finally {
       sl.unlock(stamp); // 释放所有锁
     }
   }
}}
```

> 乐观读锁的意思就是先假定在这个锁获取期间，共享变量不会改变，那就不需要上锁。在获取乐观读锁之后进行了一些操作，然后又调用了validate方法，这个方法就是用来验证tryOptimisticRead之后，是否有写操作执行过，如果有，则获取一个悲观读锁，这里的悲观读锁和ReentrantReadWriteLock种的读锁类似，也是一个共享锁。

可以看到，StampedLock获取锁会返回一个long类型的变量，释放锁的时候再把这个变量传进去。

```java
// 用于操作state后获取stamp的值
private static final int LG_READERS = 7;
private static final long RUNIT = 1L;               //0000 0000 0001
private static final long WBIT  = 1L << LG_READERS; //0000 1000 0000
private static final long RBITS = WBIT - 1L;        //0000 0111 1111
private static final long RFULL = RBITS - 1L;       //0000 0111 1110
private static final long ABITS = RBITS | WBIT;     //0000 1111 1111
private static final long SBITS = ~RBITS;           //1111 1000 0000

// 初始化时state的值
private static final long ORIGIN = WBIT << 1;       //0001 0000 0000

// 锁共享变量state
private transient volatile long state;
// 读锁溢出时用来存储多出的读锁
private transient int readerOverflow;
```

StampedLock用这个long类型的变量的前7位（LG_READERS）来表示读锁，每获取一个悲观读锁，就加1（RUNIT），每释放一个悲观读锁，就减1。而悲观读锁最多只能装128个（7位限制），很容易溢出，所以用一个int类型的变量来存储溢出的悲观读锁。
写锁用state变量剩下的位来表示，每次获取一个写锁，就加0000 1000 0000（WBIT）。需要注意的是，写锁在释放的时候，并不是减WBIT，而是再加WBIT。这是为了让每次写锁都留下痕迹，解决CAS中的ABA问题，也为乐观锁检查变化validate方法提供基础。
乐观读锁就比较简单了，并没有真正改变state的值，而是在获取锁的时候记录state的写状态，在操作完成后去检查state的写状态部分是否发生变化，上文提到了，每次写锁都会留下痕迹，也是为了这里乐观锁检查变化提供方便。
总的来说，StampedLock的性能是非常优异的，基本上可以取代ReentrantReadWriteLock的作用。

# 并发集合容器简介

## 同步容器与并发容器

```java
public class TestVector {
    private Vector<String> vector;

    //方法一
    public  Object getLast(Vector vector) {
        int lastIndex = vector.size() - 1;
        return vector.get(lastIndex);
    }

    //方法二
    public  void deleteLast(Vector vector) {
        int lastIndex = vector.size() - 1;
        vector.remove(lastIndex);
    }

    //方法三
    public  Object getLastSysnchronized(Vector vector) {
        synchronized(vector){
            int lastIndex = vector.size() - 1;
            return vector.get(lastIndex);
        }
    }

    //方法四
    public  void deleteLastSysnchronized(Vector vector) {
        synchronized (vector){
            int lastIndex = vector.size() - 1;
            vector.remove(lastIndex);
        }
    }

}
```

如果方法一和方法二为一个组合的话。那么当方法一获取到了`vector`的size之后，方法二已经执行完毕，这样就导致程序的错误。

如果方法三与方法四组合的话。通过锁机制保证了在`vector`上的操作的原子性。

并发容器是Java 5提供的在多线程变成下用于代替同步容器，针对不同的应用场景进行设计，提高容器的并发访问性，同时定义了线程安全的复合操作。


## 并发容器类介绍

整体架构（列举常用的容器类）

![img](D:\file\note\study-note\多线程.assets\assets%2F-L_5HvtIhTFW9TQlOF8e%2F-L_5TIKcBFHWPtY3OwUo%2F-L_5TIqiTZQ7Me5TObhp%2F并发容器-16393815459042.png)


### 并发Map

ConcurrentMap接口

concurrentMap接口继承了Map接口，在Map接口的基础上又定义了四个方法:

```java
public interface ConcurrentMap<K, V> extends Map<K, V> {

    //插入元素
    V putIfAbsent(K key, V value);

    //移除元素
    boolean remove(Object key, Object value);

    //替换元素
    boolean replace(K key, V oldValue, V newValue);

    //替换元素
    V replace(K key, V value);

}
```

**putIfAbsent：**与原有put方法不同的是，putIfAbsent方法种如果插入的key相同，则不替换原有的value值;

**remove：**与原有remove方法不同的是，新remove方法种增加了对value的判断，如果要删除的key-value不能与Map种原有的key-value对应上，则不会删除元素。

**replace(K.V.V):**增加了对value值得判断，如果key-oldValue能与Map种原有得key-value对应上，才进行替换操作;

**replace(K,V):**与上面的replace不同的是，此replace不会对Map种原有的key-value进行比较，如果key存在则直接替换；


**ConcurrentHashMap类**

ConcurrentHashMap同HashMap一样也是基于散列表的map，但是它提供了一种与HashTable完全不同的加锁策略提供更高效的并发性和伸缩性。

ConcurrentHashMap提供了一种粒度更细的加锁机制来实现在多线程下更高的性能，这种机制叫分段锁(lock Striping)

提供的优点是:在并发环境下将实现更高的吞吐量，而在单线程环境下只损失非常小的性能。

可以这样理解分段锁，就是将数据分段，对每一段数据分配一把锁。当一个线程占用锁访问一段数据的时候，其它段的数据也能被其它线程访问。

有些方法需要跨段，比如size()、isEmpty()、containsValue()、它们可能需要锁定整个表而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁。如下图:

ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁ReentrantLock，HashEntry则由于存储键值对数据。

一个ConcurrnetHashMap里包含一个Segment数组，Segment的结构和HashMap类似，是一种数组和链表结构，以恶搞Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构(同HashMap一样，它也会在长度达到8的时候转化为红黑树)的元素，每个Segment守护者一个HashEntry数组里的元素，当对hashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。

ConcurrnetNavigableMap接口与ConcurrentSkipListMap类

ConcurrentNavigableMap接口继承了NavigableMap接口，这个接口提供了针对给定搜索目标返回最接近匹配项的导航方法。

ConcurrentNavigableMap接口的主要实现类是ConcurrentSkipListMap类。从名字上来看，它的底层使用的是跳表(SkipList)的数据结构。关于跳表的数据结构这里不做太多介绍，它是一种"空间换时间"的数据结构，可以使用CAS来保证并发安全性。

### 并发Queue

JDK并没有提供线程安全的List类，因为对List来说，很难去开发一个通用并且没有开发瓶颈的线程安全的List。因为简单的读操作，拿contains()这样一个操作来说，很难搜索的时候如何避免锁住整个List。

所以退一步，JDK提供了对队列和双端队列的线程安全的类:ConcurrentLinkedDeque和ConcurrentLinkedQueue。因为队列相对于List来说，有更多的限制。这两个类是使用CAS来实现线程安全的。

### 并发Set

JDK提供了ConcurrentSkipListSet，是线程安全的有序的集合。底层使用ConcurrentSkipListMap实现。

谷歌的guava框架实现了一个线程安全的ConcurrentHashSet:

```java
Set<String> s = Sets.newConcurrentHashSet();
```

# CopyOnWrite

## 什么是CopyOnWrite容器

在说到CopyOnWrite容器之前我们先来谈谈什么是CopyOnWrite机制，CopyOnWrite是1计算机设计领域中的一种优化策略，也是一种在并发场景下常用的设计思想--写入时复制思想。

那什么是写入时复制思想呢?就是当有多个调用者同时去请求一个资源数据的时候，有一个调用者出于某些原因需要对当前的数据进行修改，这个时候系统将会复制一个当前数据源的副本给调用者修改。

CopyOnWrite容器即写时复制的容器，当我们往一个容器种添加元素的时候，不直接往容器种添加，而是将当前容器进行copy,复制出来一个新的容器，然后向新容器中添加我们需要的元素，最后将容器引用指向新的容器。

这样做的好处在于，我们可以在并发的场景下对容器进行"读操作"而不需要"加锁"，从而达到读写分离的目的。从JDK 1.5开始Java并发包里提供了两个使用CopyOnWrite机制实现的并发容器，分别是CopyOnWriteArrayList和CopyOnWriteArraySet。

## CopyOnWriteArrayList

优点:CopyOnWriteArrayList经常被用于"读多写少"的并发场景，是因为CopyOnWriteArrayList无需任何同步措施，大大增强了读的性能。在Java中遍历线程非安全的List(如:ArrayList和LinkedList)的时候，若中途有别的线程对List容器进行修改，那么会抛出ConcurrentModificationException异常。CopyOnwriteArrayList由于其"读写分离"，遍历和修改操作分别作用在不同的List容器，所以在使用迭代器遍历的时候，则不会抛出异常。

缺点:第一个缺点是CopyOnWriteArrayList每次执行写操作的时候都会将原容器进行拷贝了一份，数据量大时候，内存会存在较大的压力，可能会引起频繁Full GC(ZGC因为没有使用Full GC)。比如这些对象用的内存比较大200M左右，那么再写入100M数据进入，内存就会多占用300M.

第二个缺点就是CopyOnWriteArrayList由于实现的原因，写和读分别作用再不同新老容器上，在写操作执行过程中，读不会阻塞，但读取到却是老容器的数据。

现在我们来看一下CopyOnWriteArrayList的add操作源码，它的逻辑清晰，就是先把原容器进行copy，然后再新的副本上进行"写操作"，最后再切换引用，在此过程中是加了锁的。

```java
/**
     * Appends the specified element to the end of this list.
     *
     * @param e element to be appended to this list
     * @return {@code true} (as specified by {@link Collection#add})
     */
    public boolean add(E e) {

        //ReentrantLock加锁，保证线程安全
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            Object[] elements = getArray();
            int len = elements.length;
            // 拷贝原容器，长度为原容器长度加一
            Object[] newElements = Arrays.copyOf(elements, len + 1);
            // 在新副本上执行添加操作
            newElements[len] = e;
            // 将原容器引用指向新副本
            setArray(newElements);
            return true;
        } finally {
            lock.unlock();
        }
    }
```

我们再来看一下remove操作的源码，remove的逻辑是将要remove元素之外的其它元素拷贝到新的副本中，然后再切换引用，再将原容器的引用指向新的副本中，因为remove操作也是"写操作"所以也是要加锁的。

```java
public E remove(int index) {

        // 加锁
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            Object[] elements = getArray();
            int len = elements.length;
            E oldValue = get(elements, index);
            int numMoved = len - index - 1;
            if (numMoved == 0)
                // 如果要删除的是列表末端数据，拷贝前len-1个数据到新副本上，再切换引用
                setArray(Arrays.copyOf(elements, len - 1));
            else {
                // 否则，将除要删除元素之外的其他元素拷贝到新副本中，并切换引用
                Object[] newElements = new Object[len - 1];
                System.arraycopy(elements, 0, newElements, 0, index);
                System.arraycopy(elements, index + 1, newElements, index,
                                 numMoved);
                setArray(newElements);
            }
            return oldValue;
        } finally {
            // 解锁
            lock.unlock();
        }
    }
```

CopyOnWriteArrayList效率最高的读操作的源码

```java
public E get(int index) {
    return get(getArray(), index);
}
```

```java
 private E get(Object[] a, int index) {
     return (E) a[index];
 }
```

由上可见“读操作”是没有加锁，直接读取。

## CopyOnWrite的业务中的实现

接下来，我们来具体结合业务场景实现一个CopyOnWriteMap的并发容器并且使用它。

```java
import java.util.Collection;
import java.util.Map;
import java.util.Set;

public class CopyOnWriteMap<K, V> implements Map<K, V>, Cloneable {
    private volatile Map<K, V> internalMap;

    public CopyOnWriteMap() {
        internalMap = new HashMap<K, V>();
    }

    public V put(K key, V value) {
        synchronized (this) {
            Map<K, V> newMap = new HashMap<K, V>(internalMap);
            V val = newMap.put(key, value);
            internalMap = newMap;
            return val;
        }
    }

    public V get(Object key) {
        return internalMap.get(key);
    }

    public void putAll(Map<? extends K, ? extends V> newData) {
        synchronized (this) {
            Map<K, V> newMap = new HashMap<K, V>(internalMap);
            newMap.putAll(newData);
            internalMap = newMap;
        }
    }
}
```

上面就是参考CopyOnWriteArrayList实现的CopyOnWriteMap，我们可以用这个容器来做什么呢？结合我们之前说的CopyOnWrite的复制思想，它最适用于"读多写少"的并发场景。

**场景**：假如我们有一个搜索的网站需要屏蔽一些“关键字”，“黑名单”每晚定时更新，每当用户搜索的时候，“黑名单”中的关键字不会出现在搜索结果当中，并且提示用户敏感字。

```java
// 黑名单服务
public class BlackListServiceImpl {
    //　减少扩容开销。根据实际需要，初始化CopyOnWriteMap的大小，避免写时CopyOnWriteMap扩容的开销。
    private static CopyOnWriteMap<String, Boolean> blackListMap = 
        new CopyOnWriteMap<String, Boolean>(1000);

    public static boolean isBlackList(String id) {
        return blackListMap.get(id) == null ? false : true;
    }

    public static void addBlackList(String id) {
        blackListMap.put(id, Boolean.TRUE);
    }

    /**
     * 批量添加黑名单
     * (使用批量添加。因为每次添加，容器每次都会进行复制，所以减少添加次数，可以减少容器的复制次数。
     * 如使用上面代码里的addBlackList方法)
     * @param ids
     */
    public static void addBlackList(Map<String,Boolean> ids) {
        blackListMap.putAll(ids);
    }

}
```

这里需要各位小伙伴特别特别注意一个问题，此处的场景是每晚凌晨“黑名单”定时更新，原因是CopyOnWrite容器有数据一致性的问题，它只能保证最终数据一致性。
所以如果我们希望写入的数据马上能准确地读取，请不要使用CopyOnWrite容器。


# Fork/Join框架

## 什么是Fork/Join

Fork/Join框架是一个实现了ExecutorService接口的多线程的处理器它专为那些可以通过递归分解成更细小的任务而设计，最大化的利用多核处理器来提高应用程序的性能。

与其它ExecutorService相关的实现相同的是，Fork/Join框架会将任务分配给线程池中的线程。而与之不同的是，Fork/Join框架在执行任务的时候使用了工作窃取算法。

fork在英文里有分叉的意思，join在英文里连接、结合的意思。顾名思义，fork就是要使一个大人物分解成若干个小任务，而join就是最后将各个小任务的结果结合起来得到大任务的结果。

Fork/Join的运行流程大致如下所示:

![img](D:\file\note\study-note\多线程.assets\assets%2F-L_5HvtIhTFW9TQlOF8e%2F-L_5TIKcBFHWPtY3OwUo%2F-L_5TJw4VyRYbSwAlVTD%2Ffork_join流程图-16399826829682.png)

需要注意的是，图里的次级子任务可以一直分下去，一直分到子任务足够小为止。用伪代码来表示如下:

```
solve(任务):
    if(任务已经划分到足够小):
        顺序执行任务
    else:
        for(划分任务得到子任务)
            solve(子任务)
        结合所有子任务的结果到上一层循环
        return 最终结合的结果
```

通过上面伪代码可以看出，我们通过递归嵌套的计算得到最终结果，这里有体现分而治之(divide and conquer)的算法思想。

## 工作窃取算法

工作窃取算法指的是在多线程执行不同任务队列的过程中，某个线程执行完自己队列的任务后从其它线程的任务队列里窃取任务来执行。

工作窃取流程如下图所示:

![img](D:\file\note\study-note\多线程.assets\assets%2F-L_5HvtIhTFW9TQlOF8e%2F-L_5TIKcBFHWPtY3OwUo%2F-L_5TJw6YndJTY5WsZJH%2F工作窃取算法运行流程图.png)

值得注意的是，当一个线程窃取另一个线程的时候，为了减少两个任务线程之间的竞争，我们通常使用双端队列来存储任务。被窃取的子任务线程都从双端队列的头部拿任务执行，而窃取其它任务的线程从双端队列的尾部执行任务。

另外，当一个线程在窃取任务时要是没有其它可用的任务了，这个线程会进入阻塞状态以等待再次"工作"。

## Fork/Join的具体实现

前面我们说Fork/Join框架简单来讲就是对任务的分割与子任务的合并，所以要实现这个框架，先得有任务。在Fork/Join框架里提供了抽象类ForkJoinTask来实现任务。

### ForkJoinTask

ForkJoinTask是一个类似普通线程得实体，但是比普通线程轻量得多。

fork()方法:使用线程池中得空闲线程异步提交任务

```java
// 本文所有代码都引自Java 8
public final ForkJoinTask<V> fork() {
    Thread t;
    // ForkJoinWorkerThread是执行ForkJoinTask的专有线程，由ForkJoinPool管理
    // 先判断当前线程是否是ForkJoin专有线程，如果是，则将任务push到当前线程所负责的队列里去
    if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread)
        ((ForkJoinWorkerThread)t).workQueue.push(this);
    else
         // 如果不是则将线程加入队列
        // 没有显式创建ForkJoinPool的时候走这里，提交任务到默认的common线程池中
        ForkJoinPool.common.externalPush(this);
    return this;
}
```

其实fork()只做了一件事，那就是把任务推入当前工作线程的工作队列里。

join()方法:等待处理任务的线程处理完毕，获得返回值。

来看下join()的源码:

```java
public final V join() {
    int s;
    // doJoin()方法来获取当前任务的执行状态
    if ((s = doJoin() & DONE_MASK) != NORMAL)
        // 任务异常，抛出异常
        reportException(s);
    // 任务正常完成，获取返回值
    return getRawResult();
}

/**
 * doJoin()方法用来返回当前任务的执行状态
 **/
private int doJoin() {
    int s; Thread t; ForkJoinWorkerThread wt; ForkJoinPool.WorkQueue w;
    // 先判断任务是否执行完毕，执行完毕直接返回结果（执行状态）
    return (s = status) < 0 ? s :
    // 如果没有执行完毕，先判断是否是ForkJoinWorkThread线程
    ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ?
        // 如果是，先判断任务是否处于工作队列顶端（意味着下一个就执行它）
        // tryUnpush()方法判断任务是否处于当前工作队列顶端，是返回true
        // doExec()方法执行任务
        (w = (wt = (ForkJoinWorkerThread)t).workQueue).
        // 如果是处于顶端并且任务执行完毕，返回结果
        tryUnpush(this) && (s = doExec()) < 0 ? s :
        // 如果不在顶端或者在顶端却没未执行完毕，那就调用awitJoin()执行任务
        // awaitJoin()：使用自旋使任务执行完成，返回结果
        wt.pool.awaitJoin(w, this, 0L) :
    // 如果不是ForkJoinWorkThread线程，执行externalAwaitDone()返回任务结果
    externalAwaitDone();
}
```

我们在之前介绍说过Thread.join()会使线程阻塞，而ForkJoinPool.join()会使线程免入阻塞，下面是ForkJoinPool.join()的流程图:

RecursiveAction和RecursiveTask

通常情况下，在创建任务的时候我们一般不直接继承ForkJoinTask，而是继承它的子类RecursiveAction和RecursiveTask。

两个都是ForkJoinTask的子类，Recursive可以看作是无返回值的ForkJoinTask，RecursiveTask是有返回值的ForkJoinTask。

此外，两个子类都有执行主要计算的方法compute()，当然，RecursiveAction的compute()返回void，RecursiveTask的compute()有具体的返回值。

### ForkJoinPool

ForkJoinPool是用来执行ForkJoinTask任务的执行(线程)池。

ForkJoinPool管理者执行池中的线程和任务队列，此外，执行池是否还接受任务，显示线程的运行状态也是在这里处理。

我们来大致看下ForkJoinPool的源码:

```java
@sun.misc.Contended
public class ForkJoinPool extends AbstractExecutorService {
    // 任务队列
    volatile WorkQueue[] workQueues;   

    // 线程的运行状态
    volatile int runState;  

    // 创建ForkJoinWorkerThread的默认工厂，可以通过构造函数重写
    public static final ForkJoinWorkerThreadFactory defaultForkJoinWorkerThreadFactory;

    // 公用的线程池，其运行状态不受shutdown()和shutdownNow()的影响
    static final ForkJoinPool common;

    // 私有构造方法，没有任何安全检查和参数校验，由makeCommonPool直接调用
    // 其他构造方法都是源自于此方法
    // parallelism: 并行度，
    // 默认调用java.lang.Runtime.availableProcessors() 方法返回可用处理器的数量
    private ForkJoinPool(int parallelism,
                         ForkJoinWorkerThreadFactory factory, // 工作线程工厂
                         UncaughtExceptionHandler handler, // 拒绝任务的handler
                         int mode, // 同步模式
                         String workerNamePrefix) { // 线程名prefix
        this.workerNamePrefix = workerNamePrefix;
        this.factory = factory;
        this.ueh = handler;
        this.config = (parallelism & SMASK) | mode;
        long np = (long)(-parallelism); // offset ctl counts
        this.ctl = ((np << AC_SHIFT) & AC_MASK) | ((np << TC_SHIFT) & TC_MASK);
    }

}
```

**WorkQueue**

双端队列，ForkJoinTask存在这里。

当工作线程在处理自己的工作队列时，会从队列尾取任务来执行(LIFO);如果是窃取其它队列的任务时，窃取的任务位于所属任务队列的队首(FIFO)。

ForkJoinPool与传统线程池最显著的区别就是它维护了一个工作队列数组(volatile WorkQueue[] workQueues,ForkJoinPool中的每个工作线程都维护着一个工作队列)。

**runstate**

ForkJoinPool的运行状态。SHUIDOWN状态用负数表示，其它用2的幂次表示。


## Fork/Join的使用

上面我们说ForkJoinPool负责管理线程和任务，ForkJoinTask实现fork和join操作，所以要使用Fork/Join框架就离不开这两个类了，只是在实际开发中我们常用ForkJoinTask的子类RecursiveTask和RecursiveAction来替代ForkJoinTask。

下面我们用一个计算斐波那契数列第n项的例子来看一下Fork/Join的使用:

> 斐波那契数列数列是一个线性递推数列，从第三项开始，每一项的值都等于前两项之和：
1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89······
如果设f(n）为该数列的第n项（n∈N*），那么有：f(n) = f(n-1) + f(n-2)。

```JAVA
import javax.swing.plaf.synth.SynthOptionPaneUI;
import java.util.concurrent.*;

public class demo19 {

    static class Fibonacci extends RecursiveTask<Integer>{

        int n ;

        public Fibonacci(int n) {
            this.n = n;
        }

        @Override
        protected Integer compute() {
            if (n<=1){
                return n;
            }else {
                //f(n-1)
                Fibonacci f1 = new Fibonacci(n-1);
                f1.fork();
                Fibonacci f2 = new Fibonacci(n-2);
                f2.fork();
                //f(n) = f(n-1)+f(n-2);
                return f1.join()+f2.join();
            }
        }
    }

    public static void main(String[] args) throws ExecutionException, InterruptedException {
        ForkJoinPool forkJoinPool = new ForkJoinPool();
        System.out.println("CPU核心数：" + Runtime.getRuntime().availableProcessors());
        long start = System.currentTimeMillis();
        Fibonacci fibonacci = new Fibonacci(40);
        Future<Integer> future = forkJoinPool.submit(fibonacci);
        System.out.println(future.get());
        long end = System.currentTimeMillis();
        System.out.println(String.format("耗时：%d millis", end - start));

    }
}

```

上面例子在本机的输出:

```
CPU核心数：12
102334155
耗时：3235 millis
```

需要注意的是，上述计算时间复杂度为O（2^n）,随着n的增长计算效率会越来越低，这也是上面的例子中N不敢取太大的原因。

此外，也并不是所有的任务都适合Fork/join框架，比如上面的例子任务划分过于细小反而体现不出效率，下面我们试试用普通的递归来求f(n)的值，看看是不是要比使用Fork/join快:

```java
public class demo20 {

    public static int plainRecursion(int n){
        if (n == 1 || n == 2){
            return 1;
        } else {
            return plainRecursion(n - 1)+plainRecursion(n - 2);
        }
    }

    public static void main(String[] args) {
        long start = System.currentTimeMillis();
        int result = plainRecursion(40);
        long end = System.currentTimeMillis();
        System.out.println("计算结果:" + result);
        System.out.println(String.format("耗时：%d millis",  end -start));
    }

}

```

另一种计算思路:

```java
public class demo21 {

    private static int computeFibonacci(int n){
        //假设 n>=0
        if (n <= 1){
            return n;
        } else {
            int first = 1;
            int second = 1;
            int third = 0;
            for (int i = 3;i <= n; i++){
                third = first + second;
                //将两个数迁移
                first = second;
                second = third;
            }
            return third;
        }
    }

    public static void main(String[] args) {
        long start = System.currentTimeMillis();
        int result = computeFibonacci(40);
        long end = System.currentTimeMillis();
        System.out.println("计算结果:" + result);
        System.out.println(String.format("耗时：%d millis",  end -start));
    }
}
```

这里耗时为0不代表没有耗时，是表明这里计算的耗时几乎可以忽略不计，大家可以在自己的电脑试试，即使是n取大很多量级的数据（注意int溢出的问题）耗时也是很短的，或者可以用System.nanoTime()统计纳秒的时间。
为什么在这里普通的递归或循环效率更快呢？因为Fork/Join是使用多个线程协作来计算的，所以会有线程通信和线程切换的开销。
如果要计算的任务比较简单（比如我们案例中的斐波那契数列），那当然是直接使用单线程会更快一些。但如果要计算的东西比较复杂，计算机又是多核的情况下，就可以充分利用多核CPU来提高计算速度。





# CompletableFuture

我们异步执行一个任务时，一般是用线程池Executors去创建。如果不需要有返回值，任务实现Runnable接口；如果需要有返回值，任务实现Callable接口，调用Executor的submit方法，再使用Future获取即可。如果多个线程存在依赖组合的话，我们怎么处理呢?可使用同步组件CountDownLatch、CyclicBarrier等，但是比较麻烦。其实有简单的方法，就是用CompletableFuture。

## 一个例子回顾Future

因为CompletableFuture实现了Future接口，我们先来回顾Future吧。

Future是Java5新加的一个接口，它提供了一种异步并行计算的功能。如果主线程需要执行一个很耗时的计算任务，我们就可以通过Future把这个任务放到异步线程中执行。主线程继续处理其它任务，处理完成后，再通过Future获取计算结果。

来看个简单的例子，假设我们有两个任务服务，一个查询用户基本信息，一个是查询用户勋章信息。如下，

```java
public class UserInfoService {

    public UserInfo getUserInfo(Long userId) throws InterruptedException {
        Thread.sleep(300);//模拟调用耗时
        return new UserInfo("666", "捡田螺的小男孩", 27); //一般是查数据库，或者远程调用返回的
    }
}

public class MedalService {

    public MedalInfo getMedalInfo(long userId) throws InterruptedException {
        Thread.sleep(500); //模拟调用耗时
        return new MedalInfo("666", "守护勋章");
    }
}

```

在主线程如何使用Future来进行异步调用的。

```java
public class FutureTest {

    public static void main(String[] args) throws ExecutionException, InterruptedException {

        ExecutorService executorService = Executors.newFixedThreadPool(10);

        UserInfoService userInfoService = new UserInfoService();
        MedalService medalService = new MedalService();
        long userId =666L;
        long startTime = System.currentTimeMillis();

        //调用用户服务获取用户基本信息
        FutureTask<UserInfo> userInfoFutureTask = new FutureTask<>(new Callable<UserInfo>() {
            @Override
            public UserInfo call() throws Exception {
                return userInfoService.getUserInfo(userId);
            }
        });
        executorService.submit(userInfoFutureTask);

        Thread.sleep(300); //模拟主线程其它操作耗时

        FutureTask<MedalInfo> medalInfoFutureTask = new FutureTask<>(new Callable<MedalInfo>() {
            @Override
            public MedalInfo call() throws Exception {
                return medalService.getMedalInfo(userId);
            }
        });
        executorService.submit(medalInfoFutureTask);

        UserInfo userInfo = userInfoFutureTask.get();//获取个人信息结果
        MedalInfo medalInfo = medalInfoFutureTask.get();//获取勋章信息结果

        System.out.println("总共用时" + (System.currentTimeMillis() - startTime) + "ms");
    }
}
    

```

如果我们不使用Future进行并行异步调用，而是在主线程串行进行的话，耗时大约为300+500+300 = 1100ms。可以发现，future+线程池异步配合，提高了程序的执行效率。

但是Future对于结果的获取，不是很友好，只能通过阻塞或者轮询的方式得到任务的结果。

+ Future.get()就是阻塞调用，在线程获取结果之前get方法会一直阻塞。
+ Future提供了一个isDone方法，可以在程序总轮询这个方法查询执行结果。

**阻塞的方式和异步编程的涉及理念相违背，而轮询的方式耗费无谓的CPU资源。**因此，JDK8设计出CompletableFuture。CompletableFutre提供了一种观察者模式类似的机制，可以让任务完成后通知监听的一方。

## 一个例子走进CompletableFuture

我们还是基于以上Future的例子，改用CompletableFuture来实现

```java
package CompletableFuture;

import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;

public class CompletableFutureTest {

    public static void main(String[] args) throws InterruptedException, ExecutionException, TimeoutException {
        UserInfoService userInfoService = new UserInfoService();
        MedalService medalService = new MedalService();

        long start = System.currentTimeMillis();

        CompletableFuture<String> userInfoCompletableFuture = CompletableFuture.supplyAsync(() -> {
            try {
                return userInfoService.getUserInfo();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return null;
        });

        Thread.sleep(300);

        CompletableFuture<String> stringCompletableFuture = CompletableFuture.supplyAsync(() -> {
            try {
                return medalService.getMedalInfo();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return null;
        });

        String s = userInfoCompletableFuture.get(2, TimeUnit.SECONDS);
        String s1 = stringCompletableFuture.get();

        System.out.println("总共用时:"+(System.currentTimeMillis()-start)+"ms");

    }
}

```

可以发现，使用CompletableFuture，代码简洁了很多。CompletableFuture的supplyAsync方法，提供了异步执行的功能，线程池也不用单独创建了。实际上，它CompletableFuture使用了默认线程池是ForkJoinPool.commonPool。

CompletableFuture提供了几十种方法，辅助我们的异步任务场景。这些方法包括创建异步任务、异步任务回调、多个任务组合处理等方面。


## CompletableFuture使用场景

![image.png](D:\file\note\study-note\多线程.assets\0fb5ce9a8da7473ba23903a17c8beeaetplv-k3u1fbpfcp-watermark-16405733334982.awebp)


**创建异步任务**

CompletableFuture创建异步任务，一般有supplyAsync和runAsync两个方法

![image.png](D:\file\note\study-note\多线程.assets\3fea04421bac41eaad6f8286d4a670a2tplv-k3u1fbpfcp-watermark-16405733972694.awebp)

+ supplyAysnc执行CompletableFuture任务，支持返回值
+ runAsync执行CompletableFuture任务，没有返回值。

**supplyAsync方法**

```java
//使用默认内置线程池ForkJoinPool.commonPool()，根据supplier构建执行任务
public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier)
//自定义线程池，根据supplier构建任务
public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier,Executor executor)
```


**runAsync方法**

```java
//使用默认内置线程池ForkJoinPool.commonPool()，根据runnable构建执行任务
public static CompletableFuture<Void> runAsync(Runnable runnable) 
//自定义线程，根据runnable构建执行任务
public static CompletableFuture<Void> runAsync(Runnable runnable,  Executor executor)
```

实例代码如下:

```java
package CompletableFuture;

import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class demo1 {

    public static void main(String[] args) {
        //可以自定线程池
        ExecutorService executorService = Executors.newCachedThreadPool();
        //RunAsync的使用
        CompletableFuture<Void> future = CompletableFuture.runAsync(() -> System.out.println("runAsync子线程任务"), executorService);
        //supplyAsync
        CompletableFuture<String> supplyAsyncFuture = CompletableFuture.supplyAsync(() -> {
            System.out.println("supplyAsync子线程任务");
            return "supplyAsync";
        }, executorService);
        //runAsync的future没有返回值，输出null
        System.out.println(future.join());
        //supplyAsync的future有返回值
        System.out.println(supplyAsyncFuture.join());
        executorService.shutdown();
    }
}

```

任务异步回调

### thenRun/thenRunAsync

```java
public CompletableFuture<Void> thenRun(Runnable action);
public CompletableFuture<Void> thenRunAsync(Runnable action);
```

CompletableFuture的thenRun方法，通俗点讲就是，做完第一个任务后，再做第二个任务。某个任务执行完成后，执行回调方法；但是前后两个任务没有参数传递，第二个任务也没有返回值

```java
package CompletableFuture;

import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutionException;

public class demo2 {

    public static void main(String[] args) throws ExecutionException, InterruptedException {
        CompletableFuture<String> sullyAsyncFuture = CompletableFuture.supplyAsync(
                () -> {
                    System.out.println("先执行第一个CompletableFuture方法任务");
                    return "hello";
                }
        );

        CompletableFuture<Void> future = sullyAsyncFuture.thenRun(() -> {
            System.out.println("接着执行第二个任务1");
        });

        System.out.println(future.get());
    }
}

```

输出

```
先执行第一个CompletableFuture方法任务
接着执行第二个任务1
null
```

thenRun和thenRunAsynv有什么区别呢?

```java
   private static final Executor asyncPool = useCommonPool ?
        ForkJoinPool.commonPool() : new ThreadPerTaskExecutor();
        
    public CompletableFuture<Void> thenRun(Runnable action) {
        return uniRunStage(null, action);
    }

    public CompletableFuture<Void> thenRunAsync(Runnable action) {
        return uniRunStage(asyncPool, action);
    }

```

如果你执行第一个任务的时候，传入了自定义线程池:

+ 调用thenRun方法执行第二个任务时，则第二个任务和第一个任务是共用同一个线程池。
+ 调用thenRunAsync执行第二个任务时，则第一个任务使用的是你自己传入的线程池，第二个任务使用的是ForkJoin线程池

**TIPS:**后面介绍的thenAccept和thenAcceptAsync，thenApply和thenApplyAsync等，它们之间的区别也是这个哈。


### thenAccept/thenAcceptAsync

CompletableFuture的thenAccept方法表示，第一个任务执行完成后，执行第二个回调方法任务，会将该任务的执行结果，作为入参，传递到回调方法中，但是回调方法是没有返回值的。

```java
package CompletableFuture;

import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutionException;

public class demo3 {

    public static void main(String[] args) throws ExecutionException, InterruptedException {
        CompletableFuture<String> helloFuture = CompletableFuture.supplyAsync(
                () -> {
                    System.out.println("原始CompletableFuture方法任务");
                    return "hello";
                }
        );

        CompletableFuture<Void> thenAccept = helloFuture.thenAccept((a) -> {
            if ("hello".equals(a)) {
                System.out.println("hi");
            }

            System.out.println("you are so handsome");
        });

        System.out.println(thenAccept.get());
    }
}

```

### thenApply/thenApplyAsync

CompletableFuture的thenApply方法表示，第一个任务执行完成后，执行第二个回调方法任务，会将该任务的执行结果，作为入参，传递到回调方法中，并且回调方法是有返回值的。


```java
package CompletableFuture;

import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutionException;

public class demo4 {

    public static void main(String[] args) throws ExecutionException, InterruptedException {
        CompletableFuture<String> helloFuture = CompletableFuture.supplyAsync(
                () -> {
                    System.out.println("原始CompletableFuture方法任务");
                    return "hello";
                }
        );

        CompletableFuture<String> stringCompletableFuture = helloFuture.thenApply((a) -> {
            if ("hello".equals(a)) {
                return "hi";
            }
            return "How are you?";
        });

        System.out.println(stringCompletableFuture.get());
    }
}

```


### exceptionally

CompletableFuture的exceptionally方法表示，某个任务执行异常时，执行的回调方法；并且有抛出异常作为参数，传递到回调方法。

```java
package CompletableFuture;

import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutionException;

public class demo5 {

    public static void main(String[] args) throws ExecutionException, InterruptedException {
        CompletableFuture<String> subThreadFuture = CompletableFuture.supplyAsync(() -> {
            System.out.println("执行子线程" + Thread.currentThread().getName() + "方法");
            throw new RuntimeException("执行子线程任务出现异常");
        });

        CompletableFuture<String> exceptionallyFuture = subThreadFuture.exceptionally((e) -> {
            e.printStackTrace();
            return "出错了";
        });

        System.out.println(exceptionallyFuture.get());
    }
}

```

### whenComplete方法

CompletableFuture的whenCompletable方法表示，某个任务执行完成之后，执行的回调方法，无返回值；并且whenComplete方法返回的CompletableFuture的result是上个任务的结果。

```java
package CompletableFuture;

import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutionException;

public class demo6 {

    public static void main(String[] args) throws ExecutionException, InterruptedException {
        CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {
            System.out.println(Thread.currentThread().getName() + " : 执行任务");
            return "hello";
        });

        //a的类型是CompletableFuture<String>中的String
        CompletableFuture<String> stringCompletableFuture = future.whenComplete((a, throwable) -> {
            System.out.println("传递过来的参数是 ====> " + a);
            if (a.equals("hello")) {
                System.out.println("hi");
            }
            System.out.println("whenComplete方法中的线程名称是:"+Thread.currentThread().getName());
        });

        System.out.println(stringCompletableFuture.get());
    }
}

```

### handle方法

CompletableFuture的handle方法表示，某个任务执行完成之后，执行回调方法，并且是有返回值的;并且handle方法返回的CompletableFuture的result是回调方法执行的结果。

```java
package CompletableFuture;

import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutionException;

public class demo7 {

    public static void main(String[] args) throws ExecutionException, InterruptedException {
        CompletableFuture<String> stringCompletableFuture = CompletableFuture.supplyAsync(() -> {
            System.out.println("当前线程的名称:" + Thread.currentThread().getName());
            try {
                Thread.sleep(2000L);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return "hello";
        });

        CompletableFuture<String> handle = stringCompletableFuture.handle((a, throwable) -> {
            System.out.println("上个任务执行完了，还把" + a + "传过来了");
            if (a.equals("hello")) {
                System.out.println("hi");
                return "How are you";
            }
            System.out.println("fuck you ~~~");
            return null;
        });

        System.out.println(handle.get());
    }
}

```

### 多个任务组合处理

![image.png](D:\file\note\study-note\多线程.assets\67db247b585a48b88ec1dcd7ab37a8b4tplv-k3u1fbpfcp-watermark-16405921040128.awebp)

**AND组合关系**

![image.png](D:\file\note\study-note\多线程.assets\38ce935a546c42c5a11c66a26d7e19e0tplv-k3u1fbpfcp-watermark-164059212344610.awebp)


thenCombine/thenAcceptBoth/runAfterBoth都表示:将两个CompletableFuture组合起来，只有这两个都正常执行完了，才会执行某个任务。

区别在于:

+ thenCombine：会将两个任务的执行结果作为方法入参，传递到指定的方法中，且有返回值
+ thenAcceptBoth：会将两个任务的执行结果作为方法入参，传递到指定方法中，且无返回值
+ runAfterBoth:不会将执行结果当作方法入参，且没有返回值。

```java
package CompletableFuture;

import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class demo8 {

    public static void main(String[] args) {
        CompletableFuture<String> first = CompletableFuture.completedFuture("第一个异步任务");
        ExecutorService executorService = Executors.newFixedThreadPool(10);
        CompletableFuture<String> stringCompletableFuture = CompletableFuture
                //第二个异步任务
                .supplyAsync(() -> "第二个异步任务", executorService)
                //(w,s) -> System.out.println(s)是第三个任务
                .thenCombineAsync(first, (s, w) -> {
                    System.out.println(w);
                    System.out.println(s);
                    return "两个异步任务的组合";
                }, executorService);
        System.out.println(stringCompletableFuture.join());
        executorService.shutdown();
    }
}
```


### OR组合关系

![image.png](D:\file\note\study-note\多线程.assets\2d5e83e5fc4b404d980ded354bb3420dtplv-k3u1fbpfcp-watermark-164059295715412.awebp)

applyToEither/acceptEither/runAfterEither都表示：将两个CompletableFuture组合起来，只要其中一个执行完了，就会执行某个任务。

区别在于:

+ applyToEither:会将已经执行完成的任务，作为方法入参，传递到指定方法中，且有返回值。
+ acceptEither:会将已经执行完成的任务，作为方法入参，传递到指定方法中，且无返回值
+ runAfterEither:不会把执行结果当作方法入参，且没有返回值。

```java
package CompletableFuture;

import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class demo9 {

    public static void main(String[] args) {
        //第一个异步任务，休眠2秒，保证它执行晚点
        CompletableFuture<String> stringCompletableFuture = CompletableFuture.supplyAsync(() -> {
            try {
                Thread.sleep(2000L);
            } catch (InterruptedException e) {
                e.printStackTrace();
                return "第一个任务异常";
            }
            return "第一个异步任务";
        });

        ExecutorService executorService = Executors.newSingleThreadExecutor();

        CompletableFuture<Void> future = CompletableFuture
                .supplyAsync(() -> {
                    System.out.println("执行完第二个异步任务");
                    return "第二个任务";
                }, executorService)
                //第三个任务
                .acceptEitherAsync(stringCompletableFuture, System.out::println, executorService);

        executorService.shutdown();
    }
}

```


### AllOf

所有任务都执行完成后，才执行allOf返回的CompletableFutre。如果任意一个任务异常，allOf的CompletableFutre,执行get方法，会抛出异常。


```java
package CompletableFuture;

import java.util.concurrent.CompletableFuture;

public class demo10 {

    public static void main(String[] args) {
        CompletableFuture<Void> future = CompletableFuture.runAsync(() -> {
            System.out.println("我执行完了");
        });

        CompletableFuture<Void> future1 = CompletableFuture.runAsync(() -> {
            System.out.println("我也执行完了");
        });

        CompletableFuture<Void> future2 = CompletableFuture.allOf(future, future1).whenComplete((m, k) -> {
            System.out.println("finish");
        });
    }
}

```


### AnyOf

任意一个任务执行完，就执行anyOf返回的CompletableFuture。如果执行的任务异常，anyOf的CompletableFuture，执行get方法，会抛出异常


```java
package CompletableFuture;

import java.util.concurrent.CompletableFuture;

public class demo11 {

    public static void main(String[] args) {
        CompletableFuture<Void> future = CompletableFuture.runAsync(() -> {
            try {
                Thread.sleep(3000L);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println("I had done!!!");
        });

        CompletableFuture<Void> future1 = CompletableFuture.runAsync(() -> {
            System.out.println("I had done,too!!!");
        });
        CompletableFuture<Object> finish = CompletableFuture.anyOf(future, future1).whenComplete((m, k) -> {
            System.out.println("finish");
//            return "Bye";
        });
        System.out.println(finish.join());
    }
}

```

### thenCompose

thenCompose方法会在某个任务执行完成后，将该任务的执行结果，作为方法入参，去执行指定的方法。该方法会返回一个新的Completable实例

+ 如果该CompletableFuture实例的result不为null,则返回一个基于该result新的CompletableFuture实例;
+ 如果该CompletableFuture实例为null,然后就执行这个新任务

```java
package CompletableFuture;

import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class demo12 {

    public static void main(String[] args) {
        //快速创建一个返回String的CompletableFuture任务
        CompletableFuture<String> first = CompletableFuture
                .completedFuture("第一个任务");
        //第二个异步任务
        ExecutorService executorService = Executors.newSingleThreadExecutor();
        CompletableFuture<String> stringCompletableFuture = CompletableFuture
                .supplyAsync(() -> "第二个任务", executorService)
                .thenComposeAsync(data -> {
                    System.out.println(data);
                    return first; //使用第一个任务作为返回
                }, executorService);
        System.out.println(stringCompletableFuture.join());
        executorService.shutdown();
    }
}
```

### CompletableFuture使用有哪些注意点

CompletableFuture使我们的异步编程更加便利的、代码更加优雅的同时，我们也要关注下它，使用的一些注意点。

![image.png](D:\file\note\study-note\多线程.assets\eafdc009ff94437ebf1d14fee9dc1e21tplv-k3u1fbpfcp-watermark-164059534429414.awebp)

Future需要获取返回值，才能获取异常信息

```java
ExecutorService executorService = new ThreadPoolExecutor(5, 10, 5L,
    TimeUnit.SECONDS, new ArrayBlockingQueue<>(10));
CompletableFuture<Void> future = CompletableFuture.supplyAsync(() -> {
      int a = 0;
      int b = 666;
      int c = b / a;
      return true;
   },executorService).thenAccept(System.out::println);
   
 //如果不加 get()方法这一行，看不到异常信息
 //future.get();

```

Future需要获取返回值，才能获取到异常信息。如果不加get()/join()方法，看不到异常信息。

### CompletableFuture的get()方法是阻塞的。

CompletableFuture的get()方法是阻塞的，如果使用它来获取异步调用的返回值，需要添加超时时间

```java
//反例
 CompletableFuture.get();
//正例
CompletableFuture.get(5, TimeUnit.SECONDS);
```

### 默认线程池的注意点

CompletableFuture代码中又使用了默认的线程池，处理的线程个数是电脑CPU核数-1。在大量请求过来的啥时候，处理逻辑复杂的话，响应会很慢。一般建议使用自定义下次呢很难过池，优化线程池配置参数。


### 自定义线程池时，注意饱和策略

CompletableFuture的get()方法是阻塞的，我们一般建议使用future.get(3, TimeUnit.SECONDS)。并且一般建议使用自定义线程池。
但是如果线程池拒绝策略是DiscardPolicy或者DiscardOldestPolicy，当线程池饱和时，会直接丢弃任务，不会抛弃异常。因此建议，CompletableFuture线程池策略最好使用AbortPolicy，然后耗时的异步线程，做好线程池隔离哈。